var documenterSearchIndex = {"docs":
[{"location":"turing/#Hamiltonian-Monte-Carlo-with-Turing.jl","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"In this section, we will use the Turing.jl package to model the inference problem of Gaussian process regression. We advise the reader to check the Turing.jl documentation for a more detailed explanation of the package and its capabilities.","category":"page"},{"location":"turing/#Modelling-function","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Modelling function","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"In Turing we can write an observation model with the @model as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using Turing\nusing Pioran\n\n@model function inference_model(y, t, œÉ)\n\n    # Prior distribution for the parameters\n    Œ±‚ÇÅ ~ Uniform(0., 1.25)\n    f‚ÇÅ ~ LogUniform(min_f_b, max_f_b)\n    Œ±‚ÇÇ ~ Uniform(1, 4)\n    variance ~ LogNormal(log(0.5), 1.25)\n    ŒΩ ~ Gamma(2, 0.5)\n    Œº ~ Normal(0, 2)\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2\n\n    # Define power spectral density function\n    ùìü = SingleBendingPowerLaw(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximation of the PSD to form a covariance function\n    ùì° = approx(ùìü, f0, fM, 20, variance)\n\n    # Build the GP\n    f = ScalableGP(Œº,ùì°)\n\n    # sample the conditioned distribution\n    return y ~ f(t, œÉ¬≤) # <- this means that our data y is distributed according\n    # to the GP f conditioned with input t and variance œÉ¬≤\nend","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"The order of the parameters in the @model block is important, first we define the prior distribution for the parameters, then we rescale the measurement variance and define the power spectral density function and its approximation to form a covariance function. Finally, we build the Gaussian process.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"The last line says that the data y is distributed according to the Gaussian process f conditioned with input time t and measurement variance œÉ¬≤.","category":"page"},{"location":"turing/#Prior-distributions","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Prior distributions","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"In practice, if we have several slopes alpha_i and frequencies f_i, we would like to order them such that alpha_i  alpha_i+1 and f_i f_i+1. However, in Turing.jl it is not yet possible to sample from distributions with dynamic support, see these issues [1],[2],[3].","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"The solution proposed in these issues is to define a custom multivariate distribution with bijectors to map from the constrained space to the unconstrained space.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"Here we provide three distributions: TwoUniformDependent, ThreeUniformDependent and TwoLogUniformDependent.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"In a double-bending power-law model they can be used as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"@model function inference_model(y, t, œÉ)\n\n    Œ± ~ ThreeUniformDependent(0, 1.25, 4)\n    Œ±‚ÇÅ, Œ±‚ÇÇ, Œ±‚ÇÉ = Œ±\n    fb ~ TwoLogUniform(min_f_b, max_f_b)\n    f‚ÇÅ, f‚ÇÇ = fb\n    variance ~ LogNormal(log(0.5), 1.25)\n    ŒΩ ~ Gamma(2, 0.5)\n    Œº ~ LogNormal(log(3), 1)\n\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2\n    ùìü = DoubleBendingPowerLaw(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, f‚ÇÇ, Œ±‚ÇÉ)\n    ùì° = approx(ùìü, f0, fM, 20, variance)\n    f = ScalableGP(Œº, ùì°)\n    return y ~ f(t, œÉ¬≤)\nend","category":"page"},{"location":"turing/#Sampling","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Sampling","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"Once the model is defined, we can choose a sampler. Here we use the No-U-Turn Sampler (NUTS) which is a variant of Hamiltonian Monte Carlo (HMC). In Turing.jl we can define the sampler with 08  as target acceptance probability as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"sampler = NUTS(0.8)","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"or we can use the AdvancedHMC.jl package to define the sampler as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using AdvancedHMC\ntap = 0.8 #target acceptance probability\nnuts = AdvancedHMC.NUTS(tap)\nsampler = externalsampler(nuts)","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"For more information on the AdvancedHMC.jl package, see the documentation. This allows more control over the sampler, for instance the choice of metric.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"We can then sample 2000 points from the posterior distribution using the sample function. We can also specify the number of adaptation steps with the n_adapts keyword argument. The progress keyword argument is used to display the progress of the sampling process.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"mychain = sample(inference_model(y, t, yerr), sampler, 2000; n_adapts=1000, progress=true)","category":"page"},{"location":"turing/#Sampling-several-chains","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Sampling several chains","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"In practice, we may want to sample from the posterior distribution using multiple chains which is essential for convergence diagnostics hatR and the ESS (effective sample size). We can use the Distributed package or the MCMCDistributed() function to sample from the posterior distribution using multiple chains. For a more detailed explanation see the Turing.jl Guide here.","category":"page"},{"location":"turing/#With-Distributed.jl","page":"Hamiltonian Monte Carlo with Turing.jl","title":"With Distributed.jl","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"We can use the Distributed package to sample from the posterior distribution using multiple chains as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using Distributed\nusing Turing\n\nnum_chains = nworkers();\n@everywhere filename = $(ARGS[1]);\n\n@everywhere begin\n    using Turing\n    using MCMCChains\n    using AdvancedHMC\n    using Pioran\n    using DelimitedFiles\n\n    data = readdlm(filename, comments=true)\n    t, y, yerr = ...\n    # do something\nend\n\n@everywhere @model function ...\n# Define the model here\nend\n\n@everywhere begin\n    sampler = ...\nend\n\nHMCchains = pmap(c -> sample(inference_model(y, t, yerr), sampler, 2000; n_adapts=1000, progress=true), 1:num_chains)\ntotal_chainHMC = chainscat(HMCchains...) # concatenate the chains","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"This script is run with the following command:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"julia -p 6 script.jl data.txt","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"Where 6 is the number of chains and data.txt is the file containing the time series.","category":"page"},{"location":"turing/#With-MCMCDistributed()","page":"Hamiltonian Monte Carlo with Turing.jl","title":"With MCMCDistributed()","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"When using the MCMCDistributed() function, the script is essentially the same, only the last two lines are replaced by:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"total_chainHMC = sample(GP_inference(y, t, yerr), sampler, MCMCDistributed(),2000,num_chains, n_adapts=n_adapts, progress=true)","category":"page"},{"location":"turing/#Saving-the-chains","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Saving the chains","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"As mentioned in the documentation of the MCMCChains package, we can save the chains using MCMCChainsStorage as follows:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using HDF5\nusing MCMCChains\nusing MCMCChainsStorage\n\ntotal_chainHMC = sample(GP_inference(y, t, yerr), sampler, MCMCDistributed(),2000,num_chains, n_adapts=n_adapts, progress=true)\n\nh5open(\"total_chain.h5\", \"w\") do file\n    write(file, total_chainHMC)\nend","category":"page"},{"location":"turing/#Example","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Example","text":"","category":"section"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"Here is an example of a script which can be found in the example directory of the Pioran.jl package. This script is used to sample from the posterior distribution using multiple chains.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"# to run with 6 workers: julia -p 6 single_pl.jl data/simu.txt\nusing Distributed\nusing Turing\nusing HDF5\nusing MCMCChains\nusing MCMCChainsStorage\n\nnum_chains = nworkers();\n@everywhere filename = $(ARGS[1]);\n\n@everywhere begin\n    using Turing\n    using MCMCChains\n    using AdvancedHMC\n    using Pioran\n    using DelimitedFiles\n\n    fname = replace(split(filename, \"/\")[end], \".txt\" => \"_single\")\n    dir = \"inference/\" * fname\n    data = readdlm(filename, comments=true)\n    t, y, yerr = data[:, 1], data[:, 2], data[:, 3]\n\n    # Frequency range for the approx and the prior\n    f_min, f_max = 1 / (t[end] - t[1]), 1 / minimum(diff(t)) / 2\n    f0, fM = f_min / 20.0, f_max * 20.0\n    min_f_b, max_f_b = f0 * 4.0, fM / 4.0\n\n    # F var^2 is distributed as a log-normal\n    Œº·µ•, œÉ·µ• = -1.5, 1.0\n    Œº‚Çô, œÉ‚Çô¬≤ = 2Œº·µ•, 2(œÉ·µ•)^2\n    œÉ‚Çô = sqrt(œÉ‚Çô¬≤)\n\n    # options for the approximation\n    basis_function = \"SHO\"\n    n_components = 20\n    model = SingleBendingPowerLaw\n    prior_checks = true\nend\n\n@everywhere @model function inference_model(y, t, œÉ)\n\n    # Prior distribution for the parameters\n    Œ±‚ÇÅ ~ Uniform(0.0, 1.25)\n    f‚ÇÅ ~ LogUniform(min_f_b, max_f_b)\n    Œ±‚ÇÇ ~ Uniform(1, 4)\n    variance ~ LogNormal(log(0.5), 1.25)\n    ŒΩ ~ Gamma(2, 0.5)\n    Œº ~ Normal(0, 2)\n    c ~ LogUniform(1e-6, minimum(y) * 0.99)\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2 ./ (y .- c) .^ 2\n\n    # Make the flux Gaussian\n    y = log.(y .- c)\n\n    # Define power spectral density function\n    ùìü = model(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximation of the PSD to form a covariance function\n    ùì° = approx(ùìü, f0, fM, n_components, variance, basis_function=basis_function)\n\n    # Build the GP\n    f = ScalableGP(Œº, ùì°)\n\n    # sample the conditioned distribution\n    return y ~ f(t, œÉ¬≤) # <- this means that our data y is distributed according\n    # to the GP f conditioned with input t and variance œÉ¬≤\nend\n\n@everywhere begin\n    n_adapts = 500 # number of adaptation steps\n    tap = 0.8 #target acceptance probability\n    nuts = AdvancedHMC.NUTS(tap)\nend\n\n# either\n# HMCchains = sample(GP_inference(y, t, yerr), externalsampler(nuts), MCMCDistributed(),1000,num_chains, n_adapts=n_adapts, progress=true)\n# or\nHMCchains = pmap(c -> sample(inference_model(y, t, yerr), externalsampler(nuts), 1000; n_adapts=n_adapts,save_state=true, progress=true), 1:num_chains)\ntotal_chainHMC = chainscat(HMCchains...)# not needed in the previous case\n\nif !isdir(\"inference/\")\n    mkpath(\"inference/\")\nend\nh5open(dir*\".h5\", \"w\") do file\n    write(file, total_chainHMC)\nend","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"The results of the sampling can be found in the inference directory. The chains are saved in the h5 format and can be loaded as shown below:","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using MCMCChains\nusing MCMCChainsStorage\nusing HDF5\n\ntotal_chain = h5open(\"data/subset_simu_single.h5\", \"r\") do f\n  read(f, Chains)\nend\ntotal_chain","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"We can then use the StatsPlots package to visualize the chains. The first 50 points are discarded.","category":"page"},{"location":"turing/","page":"Hamiltonian Monte Carlo with Turing.jl","title":"Hamiltonian Monte Carlo with Turing.jl","text":"using StatsPlots\nplot(total_chain[50:end,:,:])","category":"page"},{"location":"adding_features/#Modelling-features-in-the-power-spectrum","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"","category":"section"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"While this package is designed to model broadband power spectral densities that are power-law-like, we can add narrow features using basis functions.","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"This feature is currently experimental and may not work properly. Use it at your own risk!","category":"page"},{"location":"adding_features/#Defining-the-model-and-simulating-form-the-model","page":"Modelling features in the power spectrum","title":"Defining the model and simulating form the model","text":"","category":"section"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"we defined a power spectral model as sum of two QPOs and a bending power-law.","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"using Plots\nusing Pioran\nusing Random\nusing Distributions\ncont = SingleBendingPowerLaw(0.5,1., 3.6)\nq1 =  QPO(7.3,0.1,2)\nq2 = QPO(9e-4,2,11)\nùìü = cont + q1 + q2\nf = 10 .^range(-3,1,1000)\np1 = Plots.plot(f,ùìü.(f),xlabel=\"Frequency (day^-1)\",ylabel=\"Power Spectral Density\",legend=true,framestyle = :box,xscale=:log10,yscale=:log10,lw=2,ylim=(1e-5,1e3),label=\"total\")\np1 = Plots.plot!(f,q1.(f),label=\"QPO1\",linestyle=:dash)\nPlots.plot!(p1,f,q2.(f),label=\"QPO2\",linestyle=:dot)\nPlots.plot!(f,cont.(f),label=\"cont\",linestyle=:dash)\np1","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"We now simulate time series from this process. To do so we will use the GP method by approximating the bending power-law with basis functions.","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"t = range(0.,1e3,step=0.1)\nyerr = 0.3*ones(length(t));","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"f_min,f_max = 1e-3,1e2\nùì° = approx(ùìü, f_min, f_max, 35, 1., basis_function=\"SHO\")\nGP = ScalableGP(0.0, ùì°)\nGPc = GP(t,yerr.^2)","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"We can sample realisations from this process:","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"rng = MersenneTwister(12)\ny = [rand(rng,GPc) for i in 1:100]\nPlots.plot(t,y[1:3],xlabel=\"Time\",ylabel=\"Value\",legend=false,framestyle = :box,ms=3)","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"As it is not very informative to look at the time series, let's compute the periodogram using Tonari.jl.","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"using Tonari\nx_GP = mapreduce(permutedims,vcat,y)\nfP,I = periodogram(t,x_GP',apply_end_matching=false)","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"Œît = t[2]-t[1]\nnoise_level = 2Œît*mean(yerr.^2)\n\nPlots.plot(fP,I,yscale=:log10,xscale=:log10,xlabel=\"Frequency (Hz)\",ylabel=\"Power\",label=\"Periodogram\",framestyle=:box)\nPlots.plot!(f,ùìü.(f),label=\"Model\",linewidth=2)\nhline!([noise_level],label=\"Noise level\",linewidth=2,linestyle=:dash,ylim=(noise_level/10,1e3),)","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"We can even compare the periodogram to the one of simulations using Timmer and K√∂nig. See the documentation of Tonari.jl for more details:","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"T, Œît = 504.2, 0.132\nsimu = Simulation(ùìü, 1e3, 0.1, 20, 20)\nrng = MersenneTwister(42)\nN = 100\nt_TK, x_TK, yerr_TK = sample(rng, simu, N, error_size = 0.25)\nfP_TK,I_TK = periodogram(t_TK,x_TK,apply_end_matching=false)","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"At the moment there is a discrepancy in the normalisations but it will be solved eventually...","category":"page"},{"location":"adding_features/","page":"Modelling features in the power spectrum","title":"Modelling features in the power spectrum","text":"Œît = t[2]-t[1]\nnoise_level = 2Œît*mean(yerr.^2)\nnoise_level_TK = 2Œît*mean(yerr_TK.^2)\n\nPlots.plot(fP,I,yscale=:log10,xscale=:log10,xlabel=\"Frequency (Hz)\",ylabel=\"Power\",framestyle=:box,label=\"Periodogram GP\",alpha=1,lw=.5)\nPlots.plot!(fP_TK,I_TK,label=\"Periodogram TK\",alpha=0.2)\nPlots.plot!(f,ùìü.(f)/2,label=\"Model\",linewidth=2)\nhline!([noise_level],label=\"Noise level\",linewidth=2,linestyle=:dash,ylim=(noise_level/4,2e2),)","category":"page"},{"location":"explanation/#Spectral-analysis-in-Pioran","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"Here we only give a brief introduction to Gaussian processes and how we use them in Pioran to infer the power spectrum of a random time series. For more details on Gaussian processes, we refer the reader to the book by Rasmussen and Williams (2006).","category":"page"},{"location":"explanation/#Gaussian-process-regression","page":"Spectral analysis in Pioran","title":"Gaussian process regression","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"A Gaussian process boldsymbolf is formally defined as a collection of random variables, any finite number of which have a joint Gaussian distribution. This process is fully described by its mean function mu(t) and its covariance function (or kernel) mathcalR(tt). The kernel must be a positive-definite function, i.e. the covariance matrix K with elements K_ij = mathcalR(t_i t_j) must be positive-definite.","category":"page"},{"location":"explanation/#Likelihood-function","page":"Spectral analysis in Pioran","title":"Likelihood function","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"Assuming data boldsymbolx(t) are generated by a Gaussian process boldsymbolf with constant mean mu and covariance function $ \\mathcal{R}(\\tau)$, a likelihood function can be derived. The log-likelihood function is given by:","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"lnmathcalL(boldsymbolthetanumu)=-frac12left( boldsymbolx - mu right)^rm T left(K +nuboldsymbolsigma^2 Iright)^-1 left( boldsymbolx - mu right) -dfrac12lnleftK +nuboldsymbolsigma^2 Iright - dfracn2ln(2pi)","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"where boldsymboltheta are the parameters of the covariance function, nu is a scale on the measurement variance, mu is the mean of the process, boldsymbolsigma^2 is the measurement noise, and n is the number of data points. In practice, Gaussian process regression is computationally expensive! The cost of evaluating this likelihood function scales as mathcalO(n^3) and the cost of storing the covariance matrix in the memory scales as mathcalO(n^2).","category":"page"},{"location":"explanation/#Conditional-Gaussian-process","page":"Spectral analysis in Pioran","title":"Conditional Gaussian process","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"The conditional distribution of the Gaussian process given the data  boldsymbolx and time values boldsymbolt, is also a Gaussian process. This new distribution can be used to make predictions at new points boldsymbolt_* and the predictive distribution is given by","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"beginaligned\nmathbbEboldsymbolf_* boldsymboltboldsymbolxboldsymbolt_* = K_* leftK +boldsymbolsigma^2 I right^-1 boldsymbolx\nmathrmCovboldsymbolf_* boldsymboltboldsymbolxboldsymbolt_* = K_** - K_* leftK +boldsymbolsigma^2 I right^-1 K_*^rm T\nendaligned","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"where K_* is the covariance matrix between the new points boldsymbolt_* and the old points boldsymbolt, and K_** is the covariance matrix between the new points boldsymbolt_*. The cost of computing the conditional distribution scales as mathcalO(n^3).","category":"page"},{"location":"explanation/#Covariance-functions-and-power-spectral-densities","page":"Spectral analysis in Pioran","title":"Covariance functions and power spectral densities","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"Here we model time series data, i.e. data indexed by time. We will assume a one-dimensional and stationary Gaussian process. In this case, the covariance function mathcalR(tt) is only a function of the time separation tau = t - t. The covariance function and the power spectral density are Fourier pairs.","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"mathcalP(f) = int_-infty^+infty mathcalR(tau) e^-2rm ipi f tau rm d tau quad  quad mathcalR(tau) = int_-infty^+infty  mathcalP(f) e^2rm ipi f tau rm d f","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"If we could compute analytically the covariance function using the inverse Fourier transform of our desired models, we could then use the covariance function to compute the likelihood function and infer the parameters of the power spectral density using Gaussian process regression. Unfortunately, it is not always easy to compute the covariance function from the power spectral density, for instance the SingleBendingPowerLaw,DoubleBendingPowerLaw model do not have closed form Fourier transforms. One could think of using the Discrete Fourier Transform (DFT) to provide an estimate of the covariance function, however it would also require interpolating the result of the DFT to populate the covariance matrix at any time lags. Additionally, this will not solve the expensive cost of evaluating the likelihood function.","category":"page"},{"location":"explanation/#Gaussian-processes-in-Pioran","page":"Spectral analysis in Pioran","title":"Gaussian processes in Pioran","text":"","category":"section"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"In Pioran.jl, we use scalable Gaussian processes to model the time series data and infer the parameters of the power spectral densities. We implement the ScalableGP type to build a Gaussian process using the AbstractGPs interface.","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"As presented above, Gaussian process regression is expensive to compute and it is not possible to describe all possible spectral densities with analytical kernels. Here we propose to use an approximation of the power spectral density by a sum of simple power spectral densities called basis functions. We choose these simple power spectral densities to be the Fourier transform of known covariance functions which have a quasi-separable structure. This enables the fast and scalable computation of the log-likelihood function using the celerite algorithm introduced in (Foreman-Mackey et al., 2017). Python implementations of the celerite algorithm are available in celerite2 and tinygp.","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"This method uses the quasi-separable structure of the covariance functions Celerite, SHO and Exp to compute the log-likelihood in a linear scaling with the number of datapoints as shown in the following benchmarks.","category":"page"},{"location":"explanation/","page":"Spectral analysis in Pioran","title":"Spectral analysis in Pioran","text":"(Image: benchmark_likelihood)","category":"page"},{"location":"carma/#Continuous-autoregressive-moving-average-(CARMA)","page":"CARMA","title":"Continuous autoregressive moving average (CARMA)","text":"","category":"section"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"Continuous autoregressive moving average (CARMA) processes are a generalization of ARMA processes to continuous time (Kelly et al., 2014) introduced CARMA processes based on the seminal work of (Jones and Ackerson, 1990), (Belcher et al., 1994) and (Jones, 1981).","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"CARMA processes can be modelled with Pioran.jl, as these can be written as a celerite process (Foreman-Mackey et al., 2017).","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"warning: Warning\nThe implementation of the CARMA process is still experimental and should be used with caution and tested thoroughly.","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"The CARMA process can be modelled with the CARMA type. The quadratic factors can be converted to roots with the quad2roots function. The roots can be converted back to quadratic factors with the roots2coeffs function. The CARMA process can be used as a kernel in the ScalableGP type.","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"note: Note\nI still have not found good priors for the parameters of the CARMA process. The priors used in the examples are not well tested and should be used with caution. Additionally, I have found difficult to assess the convergence of the MCMC chains. One might need a sampler that can handle the multimodal posterior distribution of the parameters.","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"Here are some examples of experimentals models for the CARMA process with Turing.jl.","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"@model function inference_model(y, t, œÉ, p::Int64, q::Int64)\n\n    # Priors quadratic factors\n    qa ~ filldist(FlatPos(0.),p)\n    qb ~ filldist(FlatPos(0.),q)\n\n    # Define the CARMA model\n    rŒ± = Pioran.quad2roots(qa)\n    rŒ≤ = Pioran.quad2roots(qb)\n\n    if !all(-f_max .< real.(rŒ±) .< -f_min) || !all(-f_max .< imag.(rŒ±) .< f_max)\n        Turing.@addlogprob! -Inf\n        return nothing\n    end\n\n    if !all(-f_max .< real.(rŒ≤) .< -f_min) || !all(-f_max .< imag.(rŒ≤) .<f_max)\n        Turing.@addlogprob! -Inf\n        return nothing\n    end\n\n    Œ≤ = Pioran.roots2coeffs(rŒ≤)\n\n    # Prior distribution for the parameters\n    variance ~ LogNormal(Œº‚Çô, œÉ‚Çô)\n    ŒΩ ~ Gamma(2, 0.5)\n    Œº ~ Normal(xÃÑ, 5 * sqrt(va))\n    c ~ LogUniform(1e-6, minimum(y) * 0.99)\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2 ./ (y .- c) .^ 2\n\n    # Make the flux Gaussian\n    y = log.(y .- c)\n\n    ùìí = CARMA(p, q, rŒ±, Œ≤, variance)\n\n    # Build the GP\n    f = ScalableGP(Œº, ùìí)\n\n    y ~ f(t, œÉ¬≤)\nend","category":"page"},{"location":"carma/","page":"CARMA","title":"CARMA","text":"@model function inference_model(y, t, œÉ, p::Int64, q::Int64)\n\n    # Define the LogNormal distribution for a_1\n    a1_dist = Uniform(0.0, f_max^2)\n    a2_dist = LogUniform(2 * f_min, 2 * f_max)\n    a_3 = LogUniform(f_min, f_max)\n\n    qa = Vector(undef, p)\n    qb = Vector(undef, q)\n\n      if p % 2 == 0  # all roots are complex conjugates\n          # we first fill the quadratic coefficients with pair indices\n          for i in 2:2:p\n              qa[i] ~ a2_dist\n          end\n          # then we fill the quadratic coefficients with odd indices\n          for i in 1:2:p-1\n              qa[i] ~ a1_dist + qa[i+1]^2 / 4\n          end\n\n      else\n          qa[end] ~ a_3\n\n          for i in 2:2:p-1\n              qa[i] ~ a2_dist\n          end\n          # then we fill the quadratic coefficients with odd indices\n          for i in 1:2:p-2\n              qa[i] ~ a1_dist + qa[i+1]^2 / 4\n          end\n\n      end\n\n      if q % 2 == 0  # all roots are complex conjugates\n          # we first fill the quadratic coefficients with pair indices\n          for i in 2:2:q\n              qb[i] ~ a2_dist\n          end\n          # then we fill the quadratic coefficients with odd indices\n          for i in 1:2:q-1\n              qb[i] ~ a1_dist + qb[i+1]^2 / 4\n          end\n\n        else\n            qb[end] ~ a_3\n\n            for i in 2:2:q-1\n                qb[i] ~ a2_dist\n            end\n            # then we fill the quadratic coefficients with odd indices\n            for i in 1:2:q-2\n                qb[i] ~ a1_dist + qb[i+1]^2 / 4\n            end\n\n        end\n    variance ~ LogNormal(Œº‚Çô, œÉ‚Çô)\n    ŒΩ ~ Gamma(2, 0.5)\n    Œº ~ Normal(xÃÑ, 5 * sqrt(va))\n    c ~ LogUniform(1e-6, minimum(y) * 0.99)\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2 ./ (y .- c) .^ 2\n\n    # Make the flux Gaussian\n    y = log.(y .- c)\n\n    # Define the CARMA model\n    # convert the quadratic coefficients to roots\n    rŒ± = Pioran.quad2roots(qa)\n    rŒ≤ = Pioran.quad2roots(qb)\n\n    # check that the roots are in the right range\n    if !all(-f_max .< real.(rŒ±) .< -f_min) || !all(-f_max .< imag.(rŒ±) .< f_max)\n        Turing.@addlogprob! -Inf\n        return nothing\n    end\n\n    if !all(-f_max .< real.(rŒ≤) .< -f_min) || !all(-f_max .< imag.(rŒ≤) .< f_max)\n        Turing.@addlogprob! -Inf\n        return nothing\n    end\n\n    # # check that the roots are in the right order\n    # if p % 2 == 0\n    #     permŒ± = sortperm((imag.(rŒ±[1:2:p])), rev=true)\n    # else\n    #     permŒ± = sortperm((imag.(rŒ±[1:2:p-1])), rev=true)\n    # end\n    # if permŒ± != range(1, length(permŒ±))\n    #     Turing.@addlogprob! -Inf\n    #     return nothing\n    # end\n\n    # if q % 2 == 0\n    #     permŒ≤ = sortperm((imag.(rŒ≤[1:2:q])), rev=true)\n    # else\n    #     permŒ≤ = sortperm((imag.(rŒ≤[1:2:q-1])), rev=true)\n    # end\n    # if permŒ≤ != range(1, length(permŒ≤))\n    #     Turing.@addlogprob! -Inf\n    #     return nothing\n    # end\n\n    Œ≤ = Pioran.roots2coeffs(rŒ≤)\n    ùìí = CARMA(p, q, rŒ±, Œ≤, variance)\n\n    # Build the GP\n    f = ScalableGP(Œº, ùìí)\n\n    y ~ f(t, œÉ¬≤)\n    return nothing\nend","category":"page"},{"location":"diagnostics/#Diagnostics-post-inference","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"After performing inference, we can use the Gaussian process to diagnose the quality of the fit. This can be done in the time domain or the frequency domain.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"In this section, we will work with the following time series y with measurement error yerr indexed by time t.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"using DelimitedFiles\nusing Plots\nusing CairoMakie\nusing MCMCChains\nusing PairPlots\nusing Pioran\nusing Random\n\ndata = readdlm(\"data/subset_simu_single_subset_time_series.txt\",comments=true)\nt, y, yerr = data[:,1], data[:,2], data[:,3]\nPlots.scatter(t, y,yerr=yerr, label=\"data\",xlabel=\"Time (days)\",ylabel=\"Value\",legend=false,framestyle = :box,ms=3)","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"Let's take posterior samples from a run of the inference with ultranest and plot the pairplot of the samples.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"data = readdlm(\"data/inference/chains/equal_weighted_post.txt\", comments=true)\nsamples = convert(Array{Float64},reshape(Array(data[2:end,:]),(size(data[2:end,:])...,1)))\nc = Chains(samples,data[1,:])\npairplot(c)","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"We can now use the function run_posterior_predict_checks to perform the diagnostics. This function calls several other functions to plot the graphical diagnostics.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"f0, fM = 1 / (t[end] - t[1])/4.0, 1 / minimum(diff(t)) / 2 * 4.0\nbasis_function = \"SHO\"\nn_components = 20\nmodel = SingleBendingPowerLaw\nparamnames = data[1,:]\narray = data[2:end,:]","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"This function requires a function GP_model to describe the GP model used and it requires the dictionary paramnames_split to split the parameters between the PSD model, the mean or the errors.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"function GP_model(t, y, œÉ, params, basis_function=basis_function, n_components=n_components, model=model)\n\n    T = (t[end] - t[1]) # duration of the time series\n    Œît = minimum(diff(t)) # min time separation\n\n    f_min, f_max = 1 / T, 1 / Œît / 2\n\n    Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº, c = params\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2  ./ (y.-c).^2\n\n    # Define power spectral density function\n    ùìü = model(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximation of the PSD to form a covariance function\n    ùì° = approx(ùìü, f_min, f_max, n_components, variance, basis_function=basis_function)\n\n    # Build the GP\n    f = ScalableGP(Œº, ùì°)\n\n    # Condition on the times and errors\n    fx = f(t, œÉ¬≤)\n    return fx\nend","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"The associated paramnames_split can be written as follows:","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"paramnames_split = Dict(\"psd\" => [\"Œ±‚ÇÅ\", \"f‚ÇÅ\", \"Œ±‚ÇÇ\"],\n        \"norm\" => \"variance\",\n        \"scale_err\" => \"ŒΩ\",\n        \"log_transform\" =>\"c\",\n        \"mean\" => \"Œº\")","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"figs = run_posterior_predict_checks(array, paramnames,paramnames_split, t, y, yerr, model,GP_model, true; S_low=20., S_high=20., path=\"\", basis_function=basis_function, n_components=n_components, is_integrated_power=false)","category":"page"},{"location":"diagnostics/#In-the-Fourier-domain","page":"Diagnostics post-inference","title":"In the Fourier domain","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"We can plot the posterior predictive distribution of the power spectral density and the approximate power spectral density. We can verify if the approximation is valid with the posterior samples. The noise level is given by 2 nu sigma^2_rm yerrDelta t.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"This figure is plotted using the function Pioran.plot_psd_ppc.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"figs[1]","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"A second diagnostic in the frequency domain is the posterior predictive periodograms using the Lomb-Scargle periodogram of simulated data. Using the posterior samples, we can draw realisations of the process at the same instants t and compute the Lomb-Scargle periodogram for each realisation. To do so, we use the package LombScargle.jl. We can then compare the median of the periodogram with the periodogram of the data. This figure is plotted using the function Pioran.plot_lsp_ppc.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"figs[2]","category":"page"},{"location":"diagnostics/#In-the-time-domain","page":"Diagnostics post-inference","title":"In the time domain","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"In the time domain, we can draw realisations of the process conditioned on the observations and compare it with the data with the function Pioran.plot_ppc_timeseries. The predictive time series is plotted with the function Pioran.plot_simu_ppc_timeseries.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"figs[3]","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"note: Note\nAs mentioned in Sampling from the conditioned distribution it can be very expensive to sample from the conditioned distribution, especially if the number of points is large.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"Finally, we can compute the residuals of the realisations and the data. This figure is plotted using the function Pioran.plot_residuals_diagnostics. The distribution of the residuals is also plotted, the lower panel shows the autocorrelation of the residuals. One should note that the lags of the autocorrelation are not the same as the lags of the time series. The lags are in indexes of the residuals, therefore it may be difficult to interpret the autocorrelation in terms of time and realisation of a white noise process.","category":"page"},{"location":"diagnostics/","page":"Diagnostics post-inference","title":"Diagnostics post-inference","text":"figs[4]","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Power-spectral-densities","page":"API Reference","title":"Power spectral densities","text":"","category":"section"},{"location":"api/#Models-and-functions","page":"API Reference","title":"Models and functions","text":"","category":"section"},{"location":"api/#Pioran.approx","page":"API Reference","title":"Pioran.approx","text":"approx(psd_model, f_min, f_max, n_components=20, norm=1.0,S_low::Real=20., S_high::Real=20. ; is_integrated_power::Bool = true, basis_function=\"SHO\")\n\nApproximate the PSD with a sum of basis functions to form a covariance function. The PSD model is approximated between f0=f_min/S_low and fM=f_min*S_high. By default it is normalised by its integral from f_min to f_max but it can also be normalised by its integral from 0 to infinity using the variance argument.\n\nArguments\n\npsd_model::PowerSpectralDensity: model of the PSD\nf_min::Real: the minimum frequency in the time series\nf_max::Real: the maximum frequency in the time series\nn_components::Integer=20: the number of basis functions to use\nnorm::Real=1.0: normalisation of the PSD.\nS_low::Real=20.0: scaling factor for the lowest frequency in the approximation.\nS_high::Real=20.0: scaling factor for the highest frequency in the approximation.\nis_integrated_power::Bool = true: if the norm corresponds to integral of the PSD between f_min and f_max, if not it is the variance of the process, integral of the PSD from 0 to +inf.\nbasis_function::String=\"SHO\": the basis function to use, either \"SHO\" or \"DRWCelerite\"\n\nReturn\n\ncovariance::SumOfSemiSeparable: the covariance function\n\nExample\n\nusing Pioran\nùìü = SingleBendingPowerLaw(1.0, 1.0, 2.0)\nùì° = approx(ùìü, 1e-4, 1e-1, 30, 2.31,basis_function=\"SHO\")\n\n\n\n\n\n","category":"function"},{"location":"api/#Pioran.get_covariance_from_psd-Tuple{Any}","page":"API Reference","title":"Pioran.get_covariance_from_psd","text":" get_covariance_from_psd(psd_features)\n\nGet the covariance function from the PSD features\n\n\n\n\n\n","category":"method"},{"location":"api/#Tonari.DoubleBendingPowerLaw","page":"API Reference","title":"Tonari.DoubleBendingPowerLaw","text":" DoubleBendingPowerLaw(A, Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, f‚ÇÇ, Œ±‚ÇÉ)\n\nDouble bending power law model for the power spectral density\n\nA : the amplitude\nŒ±‚ÇÅ: the first power law index\nf‚ÇÅ: the first bend frequency\nŒ±‚ÇÇ: the second power law index\nf‚ÇÇ: the second bend frequency\nŒ±‚ÇÉ: the third power law index\n\nmathcalP(f) =  Afrac(ff‚ÇÅ)^-Œ±‚ÇÅ1 + (f  f‚ÇÅ)^Œ±‚ÇÇ - Œ±‚ÇÅfrac11 + (f  f‚ÇÇ)^Œ±‚ÇÉ - Œ±‚ÇÇ\n\n\n\n\n\n","category":"type"},{"location":"api/#Tonari.Lorentzian","page":"API Reference","title":"Tonari.Lorentzian","text":"Lorentzian(A, Œ≥, f‚ÇÄ)\n\nLorentzian model for the power spectral density\n\nA: the amplitude\nŒ≥: the width of the peak\nf‚ÇÄ: the central frequency\n\nmathcalP(f) =  fracA4pi^2 (f - f‚ÇÄ)^2 + Œ≥^2\n\n\n\n\n\n","category":"type"},{"location":"api/#Tonari.PowerLaw","page":"API Reference","title":"Tonari.PowerLaw","text":" PowerLaw(Œ±)\n\nPower law model for the power spectral density\n\nŒ±: the power law index\n\nmathcalP(f) = A f^-Œ±\n\n\n\n\n\n","category":"type"},{"location":"api/#Tonari.QPO","page":"API Reference","title":"Tonari.QPO","text":"QPO(S‚ÇÄ, f‚ÇÄ,A Q)\n\nQPO model\n\nS‚ÇÄ: the amplitude at the peak\nf‚ÇÄ: the central frequency\nQ: quality factor\n\nmathcalP(f) =  fracS_0 f_0^4  left(f^ 2 -f_0^2right)^ 2 + f^2 f_0^2   Q^2 \n\n\n\n\n\n","category":"type"},{"location":"api/#Tonari.SingleBendingPowerLaw","page":"API Reference","title":"Tonari.SingleBendingPowerLaw","text":" SingleBendingPowerLaw(A, Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\nSingle bending power law model for the power spectral density\n\nA: the amplitude\nŒ±‚ÇÅ: the first power law index\nf‚ÇÅ: the first bend frequency\nŒ±‚ÇÇ: the second power law index\n\nmathcalP(f) =  A frac(ff‚ÇÅ)^-Œ±‚ÇÅ1 + (f  f‚ÇÅ)^Œ±‚ÇÇ - Œ±‚ÇÅ\n\n\n\n\n\n","category":"type"},{"location":"api/#Helper-functions","page":"API Reference","title":"Helper functions","text":"","category":"section"},{"location":"api/#Pioran.approximated_psd-Tuple{Any, PowerSpectralDensity, Real, Real}","page":"API Reference","title":"Pioran.approximated_psd","text":" approximated_psd(f, psd_model, f0, fM; n_components=20, norm=1.0, basis_function=\"SHO\")\n\nReturn the approximated PSD. This is essentially to check that the model and the approximation are consistent.\n\nArguments\n\nf::AbstractVector{<:Real}: the frequencies at which to evaluate the PSD\npsd_model::PowerSpectralDensity: model of the PSD\nf0::Real: the lowest frequency\nfM::Real: the highest frequency\nn_components::Integer=20: the number of basis functions to use\nnorm::Real=1.0: normalisation of the PSD\nbasis_function::String=\"SHO\": the basis function to use, either \"SHO\" or \"DRWCelerite\"\nindividual::Bool=false: return the individual components\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.build_approx-Tuple{Int64, Real, Real}","page":"API Reference","title":"Pioran.build_approx","text":" build_approx(J, f0, fM; basis_function=\"SHO\")\n\nPrepare the approximation of a PSD\n\nArguments\n\nJ::Integer: the number of basis functions\nf0::Real: the lowest frequency\nfM::Real: the highest frequency\nbasis_function::String=\"SHO\": the basis function to use, either \"SHO\" or \"DRWCelerite\"\n\nReturn\n\nspectral_points::Vector{Real}: the spectral points\nspectral_matrix::Matrix{Real}: the spectral matrix\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.convert_feature-Tuple{PowerSpectralDensity}","page":"API Reference","title":"Pioran.convert_feature","text":" convert_feature(psd_feature)\n\nConvert a PSD feature to a Celerite covariance function Only QPO is implemented\n\nArguments\n\npsd_feature::PowerSpectralDensity: the PSD feature\n\nReturn\n\ncovariance::SemiSeparable: the covariance function\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.get_approx_coefficients-Tuple{PowerSpectralDensity, Real, Real}","page":"API Reference","title":"Pioran.get_approx_coefficients","text":" get_approx_coefficients(psd_model, f0, fM; n_components=20, basis_function=\"SHO\")\n\nGet the coefficients of the approximated PSD\n\nArguments\n\npsd_model::PowerSpectralDensity: model of the PSD\nf0::Real: the lowest frequency\nfM::Real: the highest frequency\nn_components::Integer=20: the number of basis functions to use\nbasis_function::String=\"SHO\": the basis function to use, either \"SHO\" or \"DRWCelerite\"\n\nReturn\n\namplitudes::Vector{Real}: the amplitudes of the basis functions\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.get_norm_psd","page":"API Reference","title":"Pioran.get_norm_psd","text":"get_norm_psd(amplitudes,spectral_points,f_min,f_max,basis_function,is_integrated_power, cov_features=nothing)\n\nGet the normalisation of the sum of basis functions.\n\nArguments\n\namplitudes: amplitude of the basis function\nspectral_points: spectral points of the basis function\nf_min::Real: the minimum frequency in the time series\nf_max::Real: the maximum frequency in the time series\nbasis_function::String=\"SHO\": the basis function to use, either \"SHO\" or \"DRWCelerite\"\nis_integrated_power::Bool=true: if the norm corresponds to integral of the PSD between f_min and f_max or if it is the integral from 0 to infinity.\ncov_features: PSD features of the PSD, is nothing if there are no features.\n\n\n\n\n\n","category":"function"},{"location":"api/#Pioran.get_normalised_psd-Tuple{PowerSpectralDensity, AbstractVector{<:Real}}","page":"API Reference","title":"Pioran.get_normalised_psd","text":" get_normalised_psd(psd_model::PowerSpectralDensity, spectral_points::AbstractVector{<:Real})\n\nGet the PSD normalised at the lowest frequency\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.integral_celerite-NTuple{5, Any}","page":"API Reference","title":"Pioran.integral_celerite","text":"integral_celerite(a, b, c, d, x)\n\nComputes the integral of the Celerite power spectrum:\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.integral_drwcelerite-Tuple{Any, Any, Any}","page":"API Reference","title":"Pioran.integral_drwcelerite","text":"integral_drwcelerite(a, c, x)\n\nComputes the integral of the DRWCelerite basis function of amplitude a and width c for a given x.\n\nThe DRWCelerite basis function is defined as:\n\n    int dfraca dx(xc)^6+1 =dfracac3 left arctan(xc) +dfracsqrt34lnleft(dfracx^2+xcsqrt3+c^2x^2-xcsqrt3+c^2right)+dfrac12arctanleft(dfracx^2-c^2xcright)right\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.integral_sho-Tuple{Any, Any, Any}","page":"API Reference","title":"Pioran.integral_sho","text":"integral_sho(a, c, x)\n\nComputes the integral of the SHO basis function of amplitude a and width c for a given x.\n\nThis integral is obtained using Equation: 4.2.7.1.3 from the \"Handbook of Mathematical Formulas and Integrals\" 2009\n\n    int dfraca dx(xc)^4+1 =dfracac4sqrt2 leftlnleft(dfracx^2+cxsqrt2+c^2x^2-cxsqrt2+c^2right)+2arctanleft(dfraccxsqrt2c^2-x^2right)right\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.integrate_basis_function-NTuple{5, Any}","page":"API Reference","title":"Pioran.integrate_basis_function","text":"integrate_basis_function(a,c,x‚ÇÅ,x‚ÇÇ,basis_function)\n\nComputes the integral of the basis function between x‚ÇÅ and x‚ÇÇ for a given amplitude a and width c.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.integrate_psd_feature-NTuple{6, Any}","page":"API Reference","title":"Pioran.integrate_psd_feature","text":"integrate_psd_feature(a, b, c, d, x‚ÇÅ, x‚ÇÇ)\n\nComputes the integral of a celerite power spectral density with coefficients (a,b,c,d) between x‚ÇÅ and x‚ÇÇ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.psd_decomp-Tuple{AbstractVector{<:Real}, AbstractMatrix{<:Real}}","page":"API Reference","title":"Pioran.psd_decomp","text":" psd_decomp(psd_normalised, spectral_matrix)\n\nGet amplitudes of the basis functions by solving the linear system of the approximation\n\n\n\n\n\n","category":"method"},{"location":"api/#Tonari.separate_psd-Tuple{PowerSpectralDensity}","page":"API Reference","title":"Tonari.separate_psd","text":" separate_psd(psd::PowerSpectralDensity)\n\nSeparate the PSD into its BendingPowerLaw components and other components if it is a sum of PSDs\n\nArguments\n\npsd::PowerSpectralDensity: power spectral density or sum of PowerSpectralDensity objects\n\nReturn\n\npsd_continuum::Union{SumOfPowerSpectralDensity,PowerSpectralDensity,nothing}: continuum part of the psd\npsd_line::Union{PowerSpectralDensity,nothing,Vector{PowerSpectralDensity}}: non-continuum part of the psd\n\n\n\n\n\n","category":"method"},{"location":"api/#Covariance-functions","page":"API Reference","title":"Covariance functions","text":"","category":"section"},{"location":"api/#Models-and-functions-2","page":"API Reference","title":"Models and functions","text":"","category":"section"},{"location":"api/#Pioran.Exp","page":"API Reference","title":"Pioran.Exp","text":"Exp(A, Œ±)\n\nExponential covariance Function\n\nA: the amplitude of the covariance function\nŒ±: the decay rate of the covariance function\n\nk(œÑ) = A exp(-Œ± œÑ)\n\nExample\n\nExp(1.0, 0.25)\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.evaluate-Tuple{Exp, Any}","page":"API Reference","title":"Pioran.evaluate","text":"evaluate(R::Exp, f)\n\nThis is the right formula but it disagrees with the Celerite implementation...\n\nEvaluate the power spectral density at frequency f\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.SHO","page":"API Reference","title":"Pioran.SHO","text":" SHO(A, œâ‚ÇÄ, Q)\n\nSimple Harmonic Oscillator covariance Function\n\nA: the amplitude of the covariance function\nœâ‚ÇÄ: the angular frequency of the simple harmonic oscillator\nQ: the quality factor of the simple harmonic oscillator\n\nk(œÑ) = A exp(-œâ‚ÇÄ œÑ  Q  2) leftbeginmatrix 2(1 + œâ‚ÇÄ œÑ)  Q = 12  cos(Œ∑ œâ‚ÇÄ œÑ) + fracsin(Œ∑ œâ‚ÇÄ œÑ)2Œ∑ Q  Q  12  cosh(Œ∑ œâ‚ÇÄ œÑ) + fracsinh(Œ∑ œâ‚ÇÄ œÑ)2Œ∑ Q  Q geq 12 endmatrixright\nŒ∑ = sqrtleft1 - frac14 Q^2right\n\nSee Foreman-Mackey et al. (2017) for more details.\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.Celerite","page":"API Reference","title":"Pioran.Celerite","text":" Celerite(a, b, c, d)\n\nCelerite covariance Function\n\na: the amplitude of the first term\nb: the amplitude of the second term\nc: the decay rate of the covariance function\nd: the period of the covariance function\n\nk(œÑ) = exp(-c œÑ) (a cos(d œÑ) + b sin(d œÑ))\n\nSee Foreman-Mackey et al. (2017) for more details.\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.evaluate-Tuple{Celerite, Any}","page":"API Reference","title":"Pioran.evaluate","text":"evaluate(f, C::Celerite)\n\nevaluate the power spectral density at frequency f\n\n\n\n\n\n","category":"method"},{"location":"api/#Helper-functions-2","page":"API Reference","title":"Helper functions","text":"","category":"section"},{"location":"api/#Base.:+-Tuple{Pioran.SemiSeparable, Pioran.SemiSeparable}","page":"API Reference","title":"Base.:+","text":" +(::SemiSeparable, ::SemiSeparable)\n\nSum of semi-separable covariance functions\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.celerite_coefs-Tuple{Pioran.SumOfSemiSeparable}","page":"API Reference","title":"Pioran.celerite_coefs","text":" celerite_coefs(covariance)\n\nGet the celerite coefficients\n\n\n\n\n\n","category":"method"},{"location":"api/#Gaussian-processes","page":"API Reference","title":"Gaussian processes","text":"","category":"section"},{"location":"api/#Pioran.ScalableGP","page":"API Reference","title":"Pioran.ScalableGP","text":"ScalableGP(Œº, ùì°; solver=:celerite)\n\nScalable Gaussian Process for semi-separable covariance functions.\n\nŒº : mean or mean function of the Gaussian Process\nùì° : covariance function\nsolver : indicates which solver to use for the likelihood computation.\n\nA scalable Gaussian process has a covariance function formed of semi-separable kernels\n\nExample\n\nusing Pioran\nùìü = SingleBendingPowerLaw(1.0, 1.0, 2.0)\nùì° = approx(ùìü, 1e-4, 1e-1, 30, 2.31,basis_function=\"SHO\")\nŒº = 1.2\n\nf = ScalableGP(ùì°) # zero-mean GP\nf = ScalableGP(Œº, ùì°) # with mean Œº\n\nSee Foreman-Mackey et al. (2017) for more details.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand","page":"API Reference","title":"Base.rand","text":"rand(rng::AbstractRNG, fp::PosteriorGP, N::Int=1)\nrand(rng::AbstractRNG, fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real}, N::Int=1)\nrand(fp::PosteriorGP, N::Int=1)\n\nSample N realisations from the posterior GP fp at the points œÑ.\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractGPs.FiniteGP{<:ScalableGP}}","page":"API Reference","title":"Base.rand","text":"rand(rng::AbstractRNG, f::ScalableGP)\nrand(rng::AbstractRNG, f::ScalableGP, t::AbstractVecOrMat{<:Real})\nrand(f::ScalableGP)\nrand(f::ScalableGP, t::AbstractVecOrMat{<:Real})\n\nDraw a realisation from the GP f at the points t.\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{AbstractGPs.FiniteGP{<:ScalableGP}, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Distributions.logpdf","text":"logpdf(f::ScalableGP, Y::AbstractVecOrMat{<:Real})\n\nCompute the log-likelihood of the data Y given the GP f.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran._predict_cov-Tuple{Pioran.PosteriorGP, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Pioran._predict_cov","text":"_predict_cov(fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real})\nCompute the posterior covariance of the GP at the points œÑ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran._predict_mean-Tuple{Pioran.PosteriorGP, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Pioran._predict_mean","text":"_predict_mean(fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real})\n\nCompute the Posterior mean of the GP at the points œÑ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.posterior-Tuple{AbstractGPs.FiniteGP{<:ScalableGP}, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Pioran.posterior","text":"posterior(f::ScalableGP, y::AbstractVecOrMat{<:Real})\n\nCompute the posterior Gaussian process fp given the GP f and the data y.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.cov-Tuple{Pioran.PosteriorGP, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Statistics.cov","text":"cov(fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real})\ncov(fp::PosteriorGP)\n\nCompute the covariance of the posterior GP at the points œÑ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.mean-Tuple{Pioran.PosteriorGP, AbstractVecOrMat{<:Real}}","page":"API Reference","title":"Statistics.mean","text":"mean(fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real})\nmean(fp::PosteriorGP)\n\nCompute the mean of the posterior GP at the points œÑ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.std-Tuple{Pioran.PosteriorGP}","page":"API Reference","title":"Statistics.std","text":"std(fp::PosteriorGP, œÑ::AbstractVecOrMat{<:Real})\nstd(fp::PosteriorGP)\n\nCompute the standard deviation of the posterior GP at the points œÑ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Solvers","page":"API Reference","title":"Solvers","text":"","category":"section"},{"location":"api/#Celerite-solver","page":"API Reference","title":"Celerite solver","text":"","category":"section"},{"location":"api/#Pioran.compute_nll-NTuple{7, Any}","page":"API Reference","title":"Pioran.compute_nll","text":"compute_nll(t, y, œÉ¬≤, a, b, c, d)\n\nCompute the likelihood using the vectorised implementation in `get_values!`.\n\nStill experimental.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.get_values!-Tuple{AbstractVector, AbstractVector, AbstractVector, AbstractVector, AbstractVector, AbstractMatrix, AbstractMatrix, AbstractMatrix, AbstractVector, AbstractVector}","page":"API Reference","title":"Pioran.get_values!","text":"get_values!(a, b, c, d, zp, U, V, P, D, t)\n\nCompute the values of the matrices and vectors needed for the celerite algorithm. This is a vectorised version of the init_semi_separable! and solve_prec! functions. This function appears to be faster than the two previous functions when J > 16 but it also uses more memory.\n\nMore study of this implementation is needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.log_likelihood-Tuple{Pioran.SumOfCelerite, Any, Any, Any}","page":"API Reference","title":"Pioran.log_likelihood","text":"log_likelihood(cov, œÑ, y, œÉ2; solver = :celerite)\n\nCompute the log-likelihood of a semi-separable covariance function using the celerite algorithm.\n\nArguments\n\ncov::SumOfSemiSeparable or cov::CARMA or cov::SemiSeparable: the covariance function\nœÑ::Vector: the time points\ny::Vector: the data\nœÉ2::Vector: the measurement variances\nsolver::Symbol: solver to use for the likelihood computation either :celerite for the classic celerite solver or :celerite_matrix for the solver using matrices algebra.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.logl-NTuple{7, Any}","page":"API Reference","title":"Pioran.logl","text":"logl(a, b, c, d, œÑ, y, œÉ2)\n\nCompute the log-likelihood of a GP with a semi-separable covariance function using the celerite algorithm.\n\nArguments\n\na::Vector\nb::Vector\nc::Vector\nd::Vector\nœÑ::Vector: the time points\ny::Vector: the data\nœÉ2::Vector: the measurement variances\n\nSee Foreman-Mackey et al. (2017) for more details.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.predict-Tuple{Pioran.SumOfSemiSeparable, Vararg{AbstractVector, 4}}","page":"API Reference","title":"Pioran.predict","text":"predict(cov, œÑ, t, y, œÉ2)\n\nCompute the posterior mean of the GP at the points œÑ given the data y and time t.\n\nArguments\n\ncov::SumOfSemiSeparable or cov::CARMA or cov::SemiSeparable: the covariance function\nœÑ::Vector: the time points\nt::Vector: the data time points\ny::Vector: the data\nœÉ2::Vector: the measurement variances\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.simulate-Tuple{Random.AbstractRNG, Pioran.SumOfSemiSeparable, AbstractVector, AbstractVector}","page":"API Reference","title":"Pioran.simulate","text":"simulate(rng, cov, œÑ, œÉ2)\nsimulate(cov, œÑ, œÉ2)\n\nDraw a realisation from the  GP with the covariance function cov at the points œÑ with the variances œÉ2.\n\nArguments\n\nrng::AbstractRNG: the random number generator\ncov::SumOfSemiSeparable or cov::CARMA or cov::SemiSeparable: the covariance function\nœÑ::Vector: the time points\nœÉ2::Vector: the measurement variances\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.solve_prec!-Tuple{AbstractVector, AbstractVector, AbstractMatrix, AbstractMatrix, AbstractVector, AbstractMatrix}","page":"API Reference","title":"Pioran.solve_prec!","text":"solve_prec!(z, y, U, W, D, œï)\n\nForward and backward substitution of the celerite algorithm.\n\nSee Foreman-Mackey et al. (2017) for more details.\n\n\n\n\n\n","category":"method"},{"location":"api/#Direct-solver","page":"API Reference","title":"Direct solver","text":"","category":"section"},{"location":"api/#Pioran.log_likelihood_direct-Tuple{KernelFunctions.SimpleKernel, Vector, Vector, Vector}","page":"API Reference","title":"Pioran.log_likelihood_direct","text":"log_likelihood_direct(cov::KernelFunctions.SimpleKernel, t::Vector, y::Vector, œÉ¬≤::Vector)\n\nCompute the log-likelihood of the data Y given the GP f with the direct solver.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.predict_cov-Tuple{KernelFunctions.SimpleKernel, AbstractVector, AbstractVector, AbstractVector}","page":"API Reference","title":"Pioran.predict_cov","text":"predict_direct(cov::KernelFunctions.SimpleKernel, œÑ::AbstractVector, t::AbstractVector, œÉ¬≤::AbstractVector)\n\nCompute the posterior covariance of the GP at the points œÑ given the times t and the noise variance œÉ¬≤.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.predict_direct","page":"API Reference","title":"Pioran.predict_direct","text":"predict_direct(cov::KernelFunctions.SimpleKernel, œÑ::AbstractVector, t::AbstractVector, y::AbstractVector, œÉ¬≤::AbstractVector, with_covariance::Bool=false)\n\nCompute the posterior mean of the GP at the points œÑ given the data (t, y) and the noise variance œÉ¬≤.\n\n\n\n\n\n","category":"function"},{"location":"api/#Plotting","page":"API Reference","title":"Plotting","text":"","category":"section"},{"location":"api/#Diagnostics","page":"API Reference","title":"Diagnostics","text":"","category":"section"},{"location":"api/#Pioran.run_diagnostics","page":"API Reference","title":"Pioran.run_diagnostics","text":"run_diagnostics(prior_samples, norm_samples, f_min, f_max, model, S_low=20.0, S_high=20.0; path=\"\", basis_function=\"SHO\", n_components=20)\n\nRun the prior predictive checks for the model and the approximation of the PSD\n\nArguments\n\nprior_samples::Array{Float64, 2} : Model samples from the prior distribution\nnorm_samples::Array{Float64, 1} : The samples of the normalisation of the PSD\nf_min::Float64 : The minimum frequency of the observed data\nf_max::Float64 : The maximum frequency of the observed data\nmodel::Function : The model\nS_low::Float64=20.0 : the scaling factor for the appoximation at low frequencies\nS_high::Float64=20.0 : the scaling factor for the appoximation at high frequencies\npath::String=\"\" : The path to save the plots\nbasis_function::String=\"SHO\" : The basis function for the approximation of the PSD\nn_components::Int=20 : The number of components to use for the approximation of the PSD\n\n\n\n\n\n","category":"function"},{"location":"api/#Pioran.run_posterior_predict_checks-NTuple{9, Any}","page":"API Reference","title":"Pioran.run_posterior_predict_checks","text":"run_posterior_predict_checks(samples, paramnames, paramnames_split, t, y, yerr, model, with_log_transform; S_low = 20, S_high = 20, is_integrated_power = true, plots = \"all\", n_samples = 100, path = \"\", basis_function = \"SHO\", n_frequencies = 1000, plot_f_P = false, n_components = 20)\n\nRun the posterior predictive checks for the model and the approximation of the PSD\n\nArguments\n\nsamples::Array{Float64, 2} : The samples from the posterior distribution\nparamnames::Array{String, 1} : The names of the parameters\nparamnames_split::Dict : Dictionary to map the name of the parameters to the components for instance:                  Dict(                           \"psd\" => [\"Œ±‚ÇÅ\", \"f‚ÇÅ\", \"Œ±‚ÇÇ\"],                           \"norm\" => \"variance\",                           \"scaleerr\" => \"ŒΩ\",                           \"logtransform\" => \"c\",                           \"mean\" => \"Œº\"                       )\nt::Array{Float64, 1} : The time series\ny::Array{Float64, 1} : The values of the time series\nyerr::Array{Float64, 1} : The errors of the time series\nmodel::Function : The model or a string representing the model\nwith_log_transform::Bool : If true, the flux is log-transformed\nS_low::Float64=20.0 : the scaling factor for the appoximation at low frequencies\nS_high::Float64=20.0 : the scaling factor for the appoximation at high frequencies\nplots::String or Array{String, 1} : The type of plots to make. It can be \"all\", \"psd\", \"lsp\", \"timeseries\" or a combination of them in an array\nn_samples::Int=200 : The number of samples to draw from the posterior predictive distribution\npath::String=\"all\" : The path to save the plots\nbasis_function::String=\"SHO\" : The basis function for the approximation of the PSD\nis_integrated_power = true : if the norm corresponds to integral of the PSD between f_min and f_max or if it is the integral from 0 to infinity.\nn_frequencies::Int=1000 : The number of frequencies to use for the approximation of the PSD\nplot_f_P::Bool=false : If true, the plots are made in terms of f * PSD\nn_components::Int=20 : The number of components to use for the approximation of the PSD\nsave_samples::Bool=false : Whether to save samples of the PSD, this can create a very large file\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.sample_approx_model-NTuple{5, Any}","page":"API Reference","title":"Pioran.sample_approx_model","text":"sample_approx_model(samples, norm_samples, f0, fM, model; n_frequencies=1_000, basis_function=\"SHO\", n_components=20)\n\nCheck the approximation of the PSD by computing the residuals and the ratios of the PSD and the approximated PSD\n\nArguments\n\nsamples::Array{Float64, n} : The model samples\nnorm_samples::Array{Float64, 1} : The normalisation samples\nf0::Float64 : The minimum frequency for the approximation of the PSD\nfM::Float64 : The maximum frequency for the approximation of the PSD\nmodel::Function : The model\nn_frequencies::Int=1_000 : The number of frequencies to use for the approximation of the PSD\nbasis_function::String=\"SHO\" : The basis function for the approximation of the PSD\nn_components::Int=20 : The number of components to use for the approximation of the PSD\nis_integrated_power=true: Does the normalisation correspond to the integral of the PSD between two frequencies? If false, it corresponds to the true variance of the process.\n\nReturn\n\npsd::Array{Float64, 2} : The PSD\npsd_approx::Array{Float64, 2} : The approximated PSD\nresiduals::Array{Float64, 2} : The residuals (psd-approx_psd)\nratios::Array{Float64, 2} : The ratios (approx_psd/psd)\n\n\n\n\n\n","category":"method"},{"location":"api/#Individual-plotting-functions","page":"API Reference","title":"Individual plotting functions","text":"","category":"section"},{"location":"api/#Pioran.get_ppc_timeseries-NTuple{7, Any}","page":"API Reference","title":"Pioran.get_ppc_timeseries","text":"get_ppc_timeseries(samples, t, y, yerr, GP_model, with_log_transform; t_pred = nothing, n_samples = 1000)\n\nGet the random posterior predictive time series from the model and samples\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_boxplot_psd_approx-Tuple{Any, Any}","page":"API Reference","title":"Pioran.plot_boxplot_psd_approx","text":"plot_boxplot_psd_approx(residuals, ratios; path=\"\")\n\nPlot the boxplot of the residuals and ratios for the PSD approximation\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_lsp_ppc-NTuple{5, Any}","page":"API Reference","title":"Pioran.plot_lsp_ppc","text":"plot_lsp_ppc(samples, t, y, yerr, GP_model; plot_f_P=false, n_frequencies=1000, n_samples=1000, is_integrated_power = true, n_components=20, bin_fact=10, path=\"\", basis_function=\"SHO\",with_log_transform = true)\n\nPlot the posterior predictive Lomb-Scargle periodogram of random time series from the model to compare with the one of the data.\n\nArguments\n\nsamples::Array{Float64, n} : Posterior samples\nt::Array{Float64, 1} : Time series\ny::Array{Float64, 1} : The values of the time series\nyerr::Array{Float64, 1} : The errors of the time series\nGP_model::Function : The GP model is a function that returns a ScalableGP conditionned on t and yerr, its arguments are t,y,yerr,params\nS_low = 20.0: scaling factor for the lowest frequency in the approximation.\nS_high = 20.0: scaling factor for the highest frequency in the approximation.\nplot_f_P::Bool=false : If true, the plot is made in terms of f * PSD\nn_frequencies::Int=1000 : The number of frequencies to use for the approximation of the PSD\nn_samples::Int=1000 : The number of samples to draw from the posterior predictive distribution\nis_integrated_power::Bool = true : if the norm corresponds to integral of the PSD between f_min and f_max or if it is the integral from 0 to infinity.\nn_components::Int=20 : The number of components to use for the approximation of the PSD\nbin_fact::Int=10 : The binning factor for the LSP\npath::String=\"\" : The path to save the plots\nbasis_function::String=\"SHO\" : The basis function for the approximation of the PSD\nwith_log_transform = true : Apply a log transform to the data.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_mean_approx-Tuple{Any, Any, Any}","page":"API Reference","title":"Pioran.plot_mean_approx","text":"plot_mean_approx(f, residuals, ratios; path=\"\")\n\nPlot the frequency-averaged residuals and ratios\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_ppc_timeseries-NTuple{7, Any}","page":"API Reference","title":"Pioran.plot_ppc_timeseries","text":"plot_ppc_timeseries(samples, t, y, yerr, GP_model, with_log_transform; t_pred = nothing, n_samples = 100, path = \"\")\n\nPlot the posterior predictive time series and the residuals\n\nArguments\n\nsamples::Matrix{Float64} : The samples of the model parameters\nt::Vector{Float64} : The time series\ny::Vector{Float64} : The values of the time series\nyerr::Vector{Float64} : The errors of the time series\nGP_model::PowerSpectralDensity : The model\nwith_log_transform::Bool : If true, the flux was log-transformed for the inference\nt_pred::Vector{Float64}=nothing : The prediction times\nn_samples::Int=100 : The number of samples to draw from the posterior predictive distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_psd_ppc-NTuple{7, Any}","page":"API Reference","title":"Pioran.plot_psd_ppc","text":"plot_psd_ppc(samples_ùìü, samples_norm, samples_ŒΩ, t, y, yerr, model; S_low = 20.0, S_high = 20.0, plot_f_P = false, n_frequencies = 1000, path = \"\", n_components = 20, basis_function = \"SHO\", is_integrated_power = true, with_log_transform = false, save_samples = false)\n\nPlot the posterior predictive power spectral density and the noise levels\n\nArguments\n\nsamples_ùìü::Array{Float64, n} : The samples of the model parameters\nsamples_norm::Array{Float64, 1} : The normalisation samples, either variance or integrated power between f_min or f_max.\nsamples_ŒΩ::Array{Float64, 1} : The ŒΩ samples\nt::Array{Float64, 1} : The time series\ny::Array{Float64, 1} : The values of the time series\nyerr::Array{Float64, 1} : The errors of the time series\nmodel::Function : The model\nS_low = 20.0: scaling factor for the lowest frequency in the approximation.\nS_high = 20.0: scaling factor for the highest frequency in the approximation.\nplot_f_P::Bool = false : If true, the plot is made in terms of f * PSD\nn_frequencies::Int = 1000 : The number of frequencies to use for the approximation of the PSD\npath::String = \"\" : The path to save the plots\nn_components::Int = 20 : The number of components to use for the approximation of the PSD\nbasis_function::String = \"SHO\" : The basis function for the approximation of the PSD\nis_integrated_power::Bool = true : if the norm corresponds to integral of the PSD between f_min and f_max or if it is the integral from 0 to infinity.\nwith_log_transform::Bool = false : If true, the flux is log-transformed.\nsave_samples::Bool = false : Save samples of the psd and approx\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_quantiles_approx-NTuple{5, Any}","page":"API Reference","title":"Pioran.plot_quantiles_approx","text":"plot_quantiles_approx(f, f_min, f_max, residuals, ratios; path=\"\")\n\nPlot the quantiles of the residuals and ratios (with respect to the approximated PSD) of the PSD\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_residuals_diagnostics-Tuple{Any, Any, Any}","page":"API Reference","title":"Pioran.plot_residuals_diagnostics","text":"plot_residuals_diagnostics(t, mean_res, res_quantiles; confidence_intervals=[95, 99], path=\"\")\n\nPlot the residuals and the autocorrelation function of the residuals\n\nArguments\n\nt::Vector{Float64} : The time series\nmean_res::Vector{Float64} : The mean of the residuals\nres_quantiles::Array{Float64, 2} : The quantiles of the residuals\nconfidence_intervals::Array{Int, 1} : The confidence intervals\npath::String=\"\" : The path to save the plot\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.plot_simu_ppc_timeseries-NTuple{5, Any}","page":"API Reference","title":"Pioran.plot_simu_ppc_timeseries","text":"plot_simu_ppc_timeseries(t_pred, ts_quantiles, t, y, yerr; path=\"\")\n\nPlot the posterior predictive simulated time series\n\nArguments\n\nt_pred::Vector{Float64} : The prediction times\nts_quantiles::Array{Float64, 2} : The quantiles of the posterior predictive time series\nt::Vector{Float64} : The time series\ny::Vector{Float64} : The values of the time series\nyerr::Vector{Float64} : The errors of the time series\npath::String=\"\" : The path to save the plot\n\n\n\n\n\n","category":"method"},{"location":"api/#Utilities","page":"API Reference","title":"Utilities","text":"","category":"section"},{"location":"api/#Pioran.check_conjugate_pair-Tuple{Vector{Complex}}","page":"API Reference","title":"Pioran.check_conjugate_pair","text":"check_conjugate_pair(r::Vector{Complex})\n\nCheck if the roots are complex conjugate pairs and negative real parts Returns true if the roots are complex conjugate pairs and false otherwise\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.check_order_imag_roots-Tuple{Any}","page":"API Reference","title":"Pioran.check_order_imag_roots","text":"check_order_imag_roots(r::Vector{Complex})\n\nCheck if the imaginary parts of the roots are in ascending order\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.check_roots_bounds-Tuple{Vector{Complex}, Float64, Float64}","page":"API Reference","title":"Pioran.check_roots_bounds","text":"check_roots_bounds(r::Vector{Complex},f_min::Float64,f_max::Float64)\n\nCheck if the roots are within the bounds of the frequency range\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.extract_subset-Tuple{Random.AbstractRNG, Vararg{Any, 4}}","page":"API Reference","title":"Pioran.extract_subset","text":"extract_subset(rng, prefix, t, y, yerr; n_perc=0.03, take_log=true, suffix=\"\")\nextract_subset(seed, prefix, t, y, yerr; n_perc=0.03, take_log=true)\n\nExtract a subset of the data for the analysis and return initial guesses for the mean and variance. Either a random number generator or a seed can be provided.\n\nArguments\n\nseed::Int64 : Seed for the random number generator.\nrng::AbstractRNG : Random number generator.\nprefix::String : Prefix for the output files.\nt::Array{Float64,1} : Time array.\ny::Array{Float64,1} : Time series array.\nyerr::Array{Float64,1} : Time series error array.\nn_perc::Float64 : Percentage of the time series to extract.\ntake_log::Bool : If true, log transform the time series for the estimation of the mean and variance.\nsuffix::String : Suffix for the output files.\n\nReturn\n\nt_subset::Array{Float64,1} : Time array of the subset.\ny_subset::Array{Float64,1} : Time series array of the subset.\nyerr_subset::Array{Float64,1} : Time series error array of the subset.\nxÃÑ::Float64 : Mean of the normal distribution for Œº.\nva::Float64 : Variance of the normal distribution for Œº.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.makelist_namessplit-Tuple{Any}","page":"API Reference","title":"Pioran.makelist_namessplit","text":"simply put entries of paramnames_split into lists even when it's a string\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.separate_samples-Tuple{Any, Any, Any}","page":"API Reference","title":"Pioran.separate_samples","text":"separate_samples(samples, paramnames, with_log_transform::Bool)\n\nSeparate the samples into the parameters of the model and the parameters of the power spectral density.\n\n\n\n\n\n","category":"method"},{"location":"api/#Prior-distributions","page":"API Reference","title":"Prior distributions","text":"","category":"section"},{"location":"api/#Pioran.ThreeUniformDependent","page":"API Reference","title":"Pioran.ThreeUniformDependent","text":"ThreeUniformDependent(a, b, c, œµ)\nThreeUniformDependent(a, b, c) (constructor with default œµ = 1e-10)\n\nMultivariate distribution to model three random variables  where the first one x1 is given by U[a,b] and the second one x2 is given by U[x1,c] and the third one x3 is given by U[x2,c]. where a<b<c.\n\na: lower bound of the first distribution\nb: upper bound of the first distribution\nc: upper bound of the second and third distribution\nœµ: small value to make sure that the lower and upper bounds of each distribution are different\n\nThis means that the lower bound of the second distribution is dependent on the value of the first distribution and so on... This is implemented to overcome the limitations of the current Turing's implementation for dependent priors with dynamic support. See the following issues for more details: [1],[2],[3].\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.TwoLogUniformDependent","page":"API Reference","title":"Pioran.TwoLogUniformDependent","text":"TwoLogUniformDependent(a, b, œµ)\nTwoLogUniformDependent(a, b) (constructor with default œµ = 1e-10\n\nMultivariate distribution to model three random variables  where the first one x1 is given by log-U[a,b] and the second one x2 is given by log-U[x1,b].\n\na: lower bound of the first distribution\nb: upper bound of the first distribution\nœµ: small value to make sure that the lower and upper bounds of each distribution are different\n\nThis means that the lower bound of the second distribution is dependent on the value of the first distribution. This is implemented to overcome the limitations of the current Turing's implementation for dependent priors with dynamic support. See the following issues for more details: [1],[2],[3].\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.TwoUniformDependent","page":"API Reference","title":"Pioran.TwoUniformDependent","text":"TwoUniformDependent(a, b, c, œµ)\nTwoUniformDependent(a, b, c) (constructor with default œµ = 1e-10)\n\nMultivariate distribution to model two random variables  where the first one is given by U[a,b] and the second one is given by U[x,c], where x is a random variable sampled from the first distribution.\n\na: lower bound of the first distribution\nb: upper bound of the first distribution\nc: upper bound of the second distribution\nœµ: small value to make sure that the lower and upper bounds of each distribution are different\n\nThis means that the lower bound of the second distribution is dependent on the value of the first distribution.This is implemented to overcome the limitations of the current Turing's implementation for dependent priors with dynamic support. See the following issues for more details: [1],[2],[3].\n\nExample\n\n#```jldoctest julia> using Pioran, Distributions julia> d = TwoUniformDependent(0, 1, 2) TwoUniformDependent(0.0, 1.0, 2.0)\n\njulia> rand(d) 2-element Array{Float64,1}:  0.123  1.234 #```\n\n\n\n\n\n","category":"type"},{"location":"api/#Bijectors.bijector-Tuple{TwoUniformDependent}","page":"API Reference","title":"Bijectors.bijector","text":"Bijectors.bijector(d::TwoUniformDependent)\n\nCreate a bijector for the TwoUniformDependent distribution. This is used to sample from the distribution using the Bijectors package. Adapted from the following issues [1],[2],[3].\n\n\n\n\n\n","category":"method"},{"location":"api/#CARMA","page":"API Reference","title":"CARMA","text":"","category":"section"},{"location":"api/#Pioran.CARMA","page":"API Reference","title":"Pioran.CARMA","text":"CARMA(p, q, rŒ±, Œ≤, œÉ¬≤)\n\nContinuous-time AutoRegressive Moving Average (CARMA) model for the power spectral density\n\np: the order of the autoregressive polynomial\nq: the order of the moving average polynomial\nrŒ±: roots of the autoregressive polynomial length p+1\nŒ≤: the moving average coefficients length q+1\nœÉ¬≤: the variance of the process\n\nThe power spectral density of the CARMA model is given by:\n\nmathcalP(f) = sigma^2 leftdfracsumlimits_k=0^q beta_k left(2pimathrmifright)^k sumlimits_l=0^p alpha_l left(2pimathrmifright)^lright^2\n\n\n\n\n\n","category":"type"},{"location":"api/#Pioran.evaluate-Tuple{CARMA, Any}","page":"API Reference","title":"Pioran.evaluate","text":"evaluate(model::CARMA, f)\n\nevaluate the power spectral density of the CARMA model at frequency f.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.quad2roots-Tuple{Any}","page":"API Reference","title":"Pioran.quad2roots","text":"quad2roots(quad)\n\nConvert the coefficients of a quadratic polynomial to its roots.\n\nArguments\n\nquad::Vector{Real}: Coefficients of the quadratic polynomial.\n\nReturns\n\nr::Vector{Complex}: Roots of the polynomial.\n\n\n\n\n\n","category":"method"},{"location":"api/#Pioran.roots2coeffs-Tuple{Any}","page":"API Reference","title":"Pioran.roots2coeffs","text":"roots2coeffs(r)\n\nConvert the roots of a polynomial to its coefficients.\n\nArguments\n\nr::Vector{Complex}: Roots of the polynomial.\n\nReturns\n\nc::Vector{Complex}: Coefficients of the polynomial.\n\n\n\n\n\n","category":"method"},{"location":"ultranest/#Nested-sampling-with-ultranest","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"In this example, we show how to use the Python package ultranest to perform inference on a simple model with nested sampling. We also show how to use the ultranest[1] package with MPI to parallelise the sampling on multiple processes.","category":"page"},{"location":"ultranest/#Installation","page":"Nested sampling with ultranest","title":"Installation","text":"","category":"section"},{"location":"ultranest/#Install-the-Python-environment","page":"Nested sampling with ultranest","title":"Install the Python environment","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"It is recommended to use a virtual environment to install the required Python packages. To create a new virtual environment, run the following command in your terminal. If you are using conda, you can create a new environment with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"conda create -n julia_ultranest python=3.10","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"Then, activate the environment:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"conda activate julia_ultranest","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"You can then install ultranest with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"conda install -c conda-forge ultranest","category":"page"},{"location":"ultranest/#Install-the-Julia-environment","page":"Nested sampling with ultranest","title":"Install the Julia environment","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"To use ultranest with Julia, you need to install the PyCall package.  In the Julia REPL, set the PYTHON environment variable to the path of the Python executable in the virtual environment you created earlier. For example:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"ENV[\"PYTHON\"] = \"/opt/miniconda3/envs/julia_ultranest/bin/python\"","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"You can do this by running the following commands in the Julia REPL:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using Pkg; Pkg.add(\"PyCall\")\nPkg.build(\"PyCall\")","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"We can check that the Python environment has been set correctly by running the following commands in the Julia REPL:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using PyCall\nPyCall.python","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"Finally, ultranest can be loaded in Julia with the following commands:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"ultranest = pyimport(\"ultranest\")","category":"page"},{"location":"ultranest/#Install-MPI.jl-(optional)","page":"Nested sampling with ultranest","title":"Install MPI.jl (optional)","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"If you want to parallelise the sampling with MPI, you first have to install MPI on your system. On Ubuntu, you can install the openmpi package with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"sudo apt-get install openmpi-bin libopenmpi-dev","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"You can then install MPI.jl and MPIPreferences.jl in Julia with the following commands:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using Pkg; Pkg.add(\"MPI\")\nPkg.add(\"MPIPreferences\")","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"As detailed in the official documentation of MPI.jl[2], the system MPI binary can be linked to Julia with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"julia --project -e 'using MPIPreferences; MPIPreferences.use_system_binary()'","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"More information on how to configure MPI on can be found in the official documentation of MPI.jl.","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"The following lines of code can be used to initialise MPI in a Julia script:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using MPI\nMPI.Init()","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"note: Issues with H5PY\nSometimes, when running the code with ultranest and MPI you can get a weird error from hdf5. The common way to solve this is to reinstall h5py with support for MPI (here openmpi) as follows:conda install -c conda-forge h5py=*=mpi_openmpi*","category":"page"},{"location":"ultranest/#Modelling-with-ultranest","page":"Nested sampling with ultranest","title":"Modelling with ultranest","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"We assume the reader is familiar with nested sampling and the ultranest package.","category":"page"},{"location":"ultranest/#Priors","page":"Nested sampling with ultranest","title":"Priors","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"Priors are defined using the quantile function and probability distributions from the Distributions package. The prior_transform function is then used to transform the unit cube to the prior space as shown in the following example:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using Distributions\n\nfunction prior_transform(cube)\n    Œ±‚ÇÅ = quantile(Uniform(0.0, 1.25), cube[1])\n    f‚ÇÅ = quantile(LogUniform(1e-3, 1e3), cube[2])\n    Œ±‚ÇÇ = quantile(Uniform(Œ±‚ÇÅ, 4.0), cube[3])\n    variance = quantile(LogNormal(-2., 1.2), cube[4])\n    ŒΩ = quantile(Gamma(2, 0.5), cube[5])\n    Œº = quantile(Normal(0., 2.), cube[6])\n    return [Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº]\nend","category":"page"},{"location":"ultranest/#Model-and-likelihood","page":"Nested sampling with ultranest","title":"Model and likelihood","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"The loglikelihood function is then defined to compute the likelihood of the model given the data and the parameters. The various instructions in the function are detailed in previous sections or examples.","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using Pioran # hide\nfunction loglikelihood(y, t, œÉ, params)\n    Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº = params\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2\n    ùìü = model(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n    ùì° = approx(ùìü, f0, fM, 20, variance)\n    f = ScalableGP(Œº, ùì°)\n    return logpdf(f(t, œÉ¬≤), y)\nend\nparamnames = [\"Œ±‚ÇÅ\", \"f‚ÇÅ\", \"Œ±‚ÇÇ\", \"variance\", \"ŒΩ\", \"Œº\"]\nlogl(params) = loglikelihood(y, t, yerr, params)","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"We can then initialise the ultranest sampler with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"sampler = ultranest.ReactiveNestedSampler(paramnames, logl, resume=true, transform=prior_transform, log_dir=\"inference_dir\", vectorized=false)","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"The inference can be started with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"results = sampler.run()","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"Finally, the results can be printed and plotted with the following commands:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"sampler.print_results()\nsampler.plot()","category":"page"},{"location":"ultranest/#Parallel-sampling-with-MPI","page":"Nested sampling with ultranest","title":"Parallel sampling with MPI","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"If you want to parallelise the sampling with MPI to speed-up the computation, follow the steps presented before and run the script with the following command:","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"mpiexec -n 4 julia script.jl","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"where 4 is the number of processes to use.","category":"page"},{"location":"ultranest/#Full-example","page":"Nested sampling with ultranest","title":"Full example","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"using MPI\nMPI.Init()\ncomm = MPI.COMM_WORLD\n\nusing Pioran\nusing Distributions\nusing Statistics\nusing Random\nusing DelimitedFiles\nusing PyCall\n# load the python package ultranest\nultranest = pyimport(\"ultranest\")\n# define the random number generator\nrng = MersenneTwister(123)\n\n# get the filename from the command line\nfilename = ARGS[1]\nfname = replace(split(filename, \"/\")[end], \".txt\" => \"_single\")\ndir = \"inference/\" * fname\nplot_path = dir * \"/plots/\"\n\n# Load the data and extract a subset for the analysis\nA = readdlm(filename, comments=true, comment_char='#')\nt_all, y_all, yerr_all = A[:, 1], A[:, 2], A[:, 3]\nt, y, yerr, xÃÑ, va = extract_subset(rng, fname, t_all, y_all, yerr_all);\n\n# Frequency range for the approx and the prior\nf_min, f_max = 1 / (t[end] - t[1]), 1 / minimum(diff(t)) / 2\nf0, fM = f_min / 20.0, f_max * 20.0\nmin_f_b, max_f_b = f0 * 4.0, fM / 4.0\n\n# F var^2 is distributed as a log-normal\nŒº·µ•, œÉ·µ• = -1.5, 1.0;\nŒº‚Çô, œÉ‚Çô¬≤ = 2Œº·µ•, 2(œÉ·µ•)^2;\nœÉ‚Çô = sqrt(œÉ‚Çô¬≤)\n\n# options for the approximation\nbasis_function = \"SHO\"\nn_components = 20\nmodel = SingleBendingPowerLaw\nposterior_checks = true\nprior_checks = true\n\nfunction loglikelihood(y, t, œÉ, params)\n\n    Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº, c = params\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2 ./ (y .- c) .^ 2\n\n    # Make the flux Gaussian\n    yn = log.(y .- c)\n\n    # Define power spectral density function\n    ùìü = model(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximation of the PSD to form a covariance function\n    ùì° = approx(ùìü, f0, fM, n_components, variance, basis_function=basis_function)\n\n    # Build the GP\n    f = ScalableGP(Œº, ùì°)\n\n    # sample the conditioned distribution\n    return logpdf(f(t, œÉ¬≤), yn)\nend\nlogl(pars) = loglikelihood(y, t, yerr, pars)\n\n# Priors\nfunction prior_transform(cube)\n    Œ±‚ÇÅ = quantile(Uniform(0.0, 1.25), cube[1])\n    f‚ÇÅ = quantile(LogUniform(min_f_b, max_f_b), cube[2])\n    Œ±‚ÇÇ = quantile(Uniform(Œ±‚ÇÅ, 4.0), cube[3])\n    variance = quantile(LogNormal(Œº‚Çô, œÉ‚Çô), cube[4])\n    ŒΩ = quantile(Gamma(2, 0.5), cube[5])\n    Œº = quantile(Normal(xÃÑ, 5 * sqrt(va)), cube[6])\n    c = quantile(LogUniform(1e-6, minimum(y) * 0.99), cube[7])\n    return [Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº, c]\nend\nparamnames = [\"Œ±‚ÇÅ\", \"f‚ÇÅ\", \"Œ±‚ÇÇ\", \"variance\", \"ŒΩ\", \"Œº\", \"c\"]\n\nif MPI.Comm_rank(comm) == 0 && prior_checks\n    unif = rand(rng, 7, 3000) # uniform samples from the unit hypercube\n    priors = mapreduce(permutedims, hcat, [prior_transform(unif[:, i]) for i in 1:3000]')# transform the uniform samples to the prior\n    run_diagnostics(priors[1:3, :], priors[4, :], f0, fM, model, f_min, f_max, path=plot_path, basis_function=basis_function, n_components=n_components)\nend\n\nprintln(\"Hello world, I am $(MPI.Comm_rank(comm)) of $(MPI.Comm_size(comm))\")\n\nprintln(\"Running sampler...\")\nsampler = ultranest.ReactiveNestedSampler(paramnames, logl, resume=true, transform=prior_transform, log_dir=dir, vectorized=false)\nresults = sampler.run()\nsampler.print_results()\nsampler.plot()\n\nif MPI.Comm_rank(comm) == 0 && posterior_checks\n    samples = readdlm(dir * \"/chains/equal_weighted_post.txt\", skipstart=1)\n    run_posterior_predict_checks(samples, paramnames, t, y, yerr, f0, fM, model, true; path=plot_path, basis_function=basis_function, n_components=n_components)\nend","category":"page"},{"location":"ultranest/#References","page":"Nested sampling with ultranest","title":"References","text":"","category":"section"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"[1]: https://johannesbuchner.github.io/UltraNest/index.html","category":"page"},{"location":"ultranest/","page":"Nested sampling with ultranest","title":"Nested sampling with ultranest","text":"[2]: https://juliaparallel.org/MPI.jl/stable/configuration/","category":"page"},{"location":"timeseries/#Time-series-and-priors","page":"Time series and priors","title":"Time series and priors","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"I usually store time series in a text file, this file can be read using the readdlm function from the DelimitedFiles package.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"using DelimitedFiles\ndata = readdlm(\"data.txt\", comments=true) # comments=true to ignore the header\nt, y, œÉ = data[:, 1], data[:, 2], data[:, 3]","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"warning: Warning\nThe time series should be sorted in ascending order of time to use the celerite algorithm.","category":"page"},{"location":"timeseries/#Log-normal-distributed-time-series","page":"Time series and priors","title":"Log-normal distributed time series","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"If we assume the time series to be log-normally distributed, we can use the log function to make it normally distributed. In addition, we need to rescale the measurement variance to account for the transformation. We also add a constant c to the time series to account for a possible offset. The parameter ŒΩ is used to rescale the measurement variance, in case the errors are underestimated or overestimated. The transformation is given by","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"    œÉ¬≤ = ŒΩ .* œÉ .^ 2 ./ (y .- c) .^ 2\n    yn = log.(y .- c)","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"Then the Gaussian process can be built as shown before:","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"    f = ScalableGP(Œº, ùì°)\n    fx = f((t, œÉ¬≤), yn)","category":"page"},{"location":"timeseries/#Defining-the-priors","page":"Time series and priors","title":"Defining the priors","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"The prior probability distribution of the parameters of the Gaussian process can be defined using the Distributions package. See the documentation for more details.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"using Distributions\nusing Plots","category":"page"},{"location":"timeseries/#Bending-power-law-parameters","page":"Time series and priors","title":"Bending power-law parameters","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"As mentioned before the power spectrum can be modelled using a bending power-law. We do not model the amplitude of the power spectrum but its integral, the variance (see below). The indices or slopes of the power spectrum are modelled with a Uniform distribution as we restrict their range for the approximation to hold. In the case of SHO basis functions, the range of the indices is between 0 and 4 and DRWCelerite is between 0 and 6. We can model slightly rising power spectra by giving a small negative lower bounder such as -0.5.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"Œ±‚ÇÅ = Uniform(-0.5, 1.5)\nŒ±‚ÇÇ = Uniform(-0.5, 4.0)\nx = range(-1, 5, length=100)\nplot(x, pdf.(Œ±‚ÇÅ, x), label=\"Œ±‚ÇÅ prior\", xlabel=\"Œ±\", ylabel=\"pdf(Œ±)\",framestyle = :box,lw=2)\nplot!(x, pdf.(Œ±‚ÇÇ, x), label=\"Œ±‚ÇÇ prior\", xlabel=\"Œ±\", ylabel=\"pdf(Œ±)\",framestyle = :box,lw=2)","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"The bend frequencies can be modelled with a log-uniform prior distribution depending on the time values of the time series. For instance, we have:","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"T = 364.3# t[end]-t[1] # duration\nŒît = 0.64#minimum(diff(t)) # minimum sampling\nf_min, f_max = 1/T, 1/2/Œît\nf0, fM = f_min / 5.0 , f_max * 5.0\n\nf‚ÇÅ = LogUniform(f0,fM)\nx = 10 .^(range(-3,2,1000))\nplot(x,pdf.(f‚ÇÅ,x),label=\"f‚ÇÅ prior\",xlabel=\"f‚ÇÅ\",ylabel=\"pdf(f‚ÇÅ)\",framestyle=:box,lw=2,xscale=:log10)\nvline!([f_min,f_max],label=\"f_min or f_max\")","category":"page"},{"location":"timeseries/#Scale-on-the-errors","page":"Time series and priors","title":"Scale on the errors","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"The parameter ŒΩ is used to rescale the measurement variance, in case the errors are underestimated or overestimated. We expect the find the value of ŒΩ to be close to 1, we model the prior distribution on ŒΩ as a gamma distribution with shape 2 and rate 0.5:","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"ŒΩ = Gamma(2, 0.5)\nx = range(0, 5, length=100)\nprintln(\"Mean: \", mean(ŒΩ), \" Variance: \", var(ŒΩ))","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"plot(x, pdf.(ŒΩ, x), label=\"ŒΩ prior\", xlabel=\"ŒΩ\", ylabel=\"pdf(ŒΩ)\",framestyle = :box,lw=2)","category":"page"},{"location":"timeseries/#Mean-of-the-time-series","page":"Time series and priors","title":"Mean of the time series","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"In a Bayesian framework defining the prior for the mean Œº and the variance variance can be challenging if we have no a priori information about the time series. A solution can be to randomly sample values from the time series and use them to define the prior distributions. The function extract_subset can be used to extract a small - 3 per cent - subset of the time series and compute the mean xÃÑ and variance va of the subset. The remaining values are returned to be used in the inference.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"If we assume the time series to be log-normally distributed then the log of the subset is taken to provide an estimate of the mean and variance this is done by setting take_log=true. See the example below:","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"seed = 1234\nt, y, œÉ, xÃÑ, va = extract_subset(seed, t_all, y_all, œÉ_all; take_log=true,suffix=\"_seed1234\")","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"The prior on the mean can be constructed using a normal distribution with the mean and variance of the subset.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"xÃÑ = 0.23 # hide\nva = 1.2# hide\nŒº = Normal(xÃÑ, 5*sqrt(va))\nx = range(-10, 10, length=1000)\nplot(x, pdf.(Œº, x), label=\"Œº prior\", xlabel=\"Œº\", ylabel=\"pdf(Œº)\",framestyle = :box,lw=2)","category":"page"},{"location":"timeseries/#Variance-of-the-time-series-for-active-galaxies","page":"Time series and priors","title":"Variance of the time series for active galaxies","text":"","category":"section"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"For astronomical light curves from active galaxies, we can constrain the variance using our prior knowledge of the fractional variability amplitude F_mathrmvar=sqrtdfracs^2-sigma^2_mathrmerrbarx^2 where s^2 is the sample variance, barx and sigma^2_mathrmerr is mean square error.  We know it is very unlikely to be higher than 1 therefore we can use a log-normal distribution. As F_mathrmvar^2 is proportional to the variance, we can assume a log-normal prior for the variance.","category":"page"},{"location":"timeseries/","page":"Time series and priors","title":"Time series and priors","text":"# Distribution for F_var\nŒº·µ•, œÉ·µ• = -1.5, 1/‚àö2\nŒº‚Çô, œÉ‚Çô¬≤ = 2Œº·µ•, 4(œÉ·µ•)^2\nvariance = LogNormal(Œº‚Çô, sqrt(œÉ‚Çô¬≤))\nx = range(1e-3, 10, length=10000)\n\nplot(x, pdf.(variance, x), label=\"variance prior\", xlabel=\"variance\", ylabel=\"pdf(variance)\",framestyle = :box,lw=2,xscale=:log10)","category":"page"},{"location":"modelling/#Modelling","page":"Modelling","title":"Modelling","text":"","category":"section"},{"location":"modelling/#Modelling-the-power-spectral-density","page":"Modelling","title":"Modelling the power spectral density","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"We use SingleBendingPowerLaw and DoubleBendingPowerLaw to model the power spectral density of the random process generating the time series data.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"using Plots\nusing Pioran\nùìü1 = SingleBendingPowerLaw(1., .1, 3.4)\nùìü2 = SingleBendingPowerLaw(.4, 1e-2, 3.)\nùìü3 = SingleBendingPowerLaw(.1, 3., 2.4)\nùìü1d = DoubleBendingPowerLaw(1.2,1e-3,2.4,1.1,4.2)\nùìü2d = DoubleBendingPowerLaw(0.2,1e-2,1.3,24.3,3.1)\nùìü3d = DoubleBendingPowerLaw(0.5,1e-3,2.1,91.2,4.9)\nf = 10 .^ range(-4, stop=3, length=1000)\nl = @layout [a b]\np1 =  plot(f,[f.*ùìü1(f),f.*ùìü2(f),f.*ùìü3(f)],xlabel=\"Frequency\",ylabel=\"Frequency * Power\",legend=false,framestyle = :box,xscale=:log10,yscale=:log10,ylims=(1e-15,1e1),lw=2)\np2 =  plot(f,[f.*ùìü1d(f),f.*ùìü2d(f),f.*ùìü3d(f)],xlabel=\"Frequency\",legend=false,framestyle = :box,xscale=:log10,yscale=:log10,ylims=(1e-15,1e1),lw=2)\nplot(p1,p2,layout=l,size=(700,300),grid=false,left_margin=2Plots.mm,bottom_margin=20Plots.px,title=[\"Single bending power-law\" \"Double bending power-law\"])","category":"page"},{"location":"modelling/#Approximating-the-power-spectral-density","page":"Modelling","title":"Approximating the power spectral density","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"To obtain the covariance function, we approximate the power spectral density by a sum of basis functions psi(f). At the moment, we use either of the following basis functions:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"beginalignbeginsplit\npsi_4(f) = frac11+f^4\npsi_6(f) = frac11+f^6\nendsplit\nendalign","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"These basis functions have analytical Fourier transforms and are used to approximate the covariance function. The Fourier transform of the basis functions are given by","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"beginalignbeginsplit\nphi_4(tau) = dfracpisqrt2 expleft(-pisqrt2tauright) left(cosleft(pisqrt2tauright)+sinleft(pisqrt2tauright)right)\nphi_6(tau) =dfracpi3expleft(-2pi tauright)+expleft(-pitauright)left(pi3cosleft(pisqrt3tauright)+pisqrt3sinleft(pisqrt3tauright)right)endsplit\nendalign","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"We need to specify the frequency range f0=f_mathrmminS_mathrmlow and fM=f_mathrmmaxS_mathrmhigh over which the approximation is performed. We also need to specify the number of basis functions J to use. Once this is done the frequency grid is defined as:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"f_j=f_0left(f_Mf_0right)^j(J-1) j=012dotsJ-1","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The approximation of the power spectral density is then given by:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"beginalign\n    mathcalP(f)simeq tildemathcalP(f)=  sumlimits_j=0^J-1 a_j psi(ff_j)\n    mathcalR(tau)simeq tildemathcalR(tau)= sumlimits_j=0^J-1 a_j f_j phi(tau f_j)\nendalign","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"Adding the constraint that the approximation and the true power spectrum must be equal on the grid of frequencies gives a linear system of J equations for the coefficients a_j. This system can be written with a Toeplitz matrix B  and a vector boldsymbola as:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"beginalign\nboldsymbolp = boldsymbola B quad textwhere  B_ij=psi(f_if_j) text and  p_j = mathcalP(f_j)mathcalP(f_0)\nendalign","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The values of p_j are divided by p_0 so that the values of a_j are not too high. Visually, the approximation can be seen as follows:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"f0, fM = 1e-3, 1e3\nùìü = SingleBendingPowerLaw(.4, 1e-1, 3.)\nf = 10 .^ range(-3, stop=3, length=1000)\npsd_approx = Pioran.approximated_psd(f, ùìü, f0, fM, n_components=20,basis_function=\"SHO\",individual=true)\n\nplot(f,ùìü(f)/ùìü(f0),xscale=:log10,yscale=:log10,label=\"True PSD\",xlabel=\"Frequency (day^-1)\",ylabel=\"Power Spectral Density\",lw=2,framestyle = :box,grid=false)\nplot!(f,sum(psd_approx,dims=2),label=\"Approximated PSD\",lw=2)\nplot!(f,psd_approx,label=nothing,color=:black,alpha=.5,ylims=(1e-15,1e1),ls=:dot)","category":"page"},{"location":"modelling/#Limitations-and-diagnostics-for-the-approximation","page":"Modelling","title":"Limitations and diagnostics for the approximation","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"warning: Limitations of the approximation\nThis approximation is limited by the steepness of the basis functions, this means that if the power spectrum you want to approximate is steeper than the basis functions, the approximation may fail. Equivalently, the basis functions are flat at low frequencies, modelling a rising power spectrum at low frequencies can also be difficult.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"In order to check the quality of the approximation, we can compute the residuals and ratios between the true and approximated power spectrum. First, we need to define the range of allowed values for each parameter to check. As we adopt a Bayesian workflow, one can use the prior distribution to define the range of allowed values for each parameter. This can be done as follows:","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"using Distributions\nusing Random\nrng = MersenneTwister(1234)\n\nmin_f_b, max_f_b = 1e-3, 1e3\nfunction prior_transform(cube)\n    Œ±‚ÇÅ = quantile(Uniform(0.0, 1.25), cube[1])\n    f‚ÇÅ = quantile(LogUniform(min_f_b, max_f_b), cube[2])\n    Œ±‚ÇÇ = quantile(Uniform(Œ±‚ÇÅ, 4.0), cube[3])\n    norm = quantile(LogNormal(-1,2), cube[4])\n    return [Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, norm]\nend\n\nP = 2000\nunif = rand(rng, 4, P)\npriors = mapreduce(permutedims, hcat, [prior_transform(unif[:, i]) for i in 1:P]')\nl = @layout [a b ; c d]\np1 = histogram(priors[1,:],xlabel=\"Œ±‚ÇÅ\")\nbins = 10.0 .^LinRange( log10(minimum(priors[2,:])),log10(quantile(priors[2,:],.99)),30)\np2 = histogram(priors[2,:],bins=bins,xaxis=(:log10,(bins[1],bins[end])),xlabel=\"f‚ÇÅ\")\np3 = histogram(priors[3,:],xlabel=\"Œ±‚ÇÇ\")\nbins = 10.0 .^LinRange( log10(minimum(priors[4,:])),log10(quantile(priors[4,:],1)),30)\np4 = histogram(priors[4,:],xlabel=\"norm\",bins=bins,xaxis=(:log10,(bins[1],bins[end])))\nplot(p1,p2,p3,p4,layout=l,size=(700,300),grid=false,left_margin=2Plots.mm,bottom_margin=20Plots.px,legend=false)","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"We can then use the function run_diagnostics to assess the quality of the approximation. The first argument is an array containing the parameters of the power spectral density, the second argument is the normalisation of the PSD of the process. f_min and f_max are the minimum and maximum frequencies of the time series, this is to show the window of observed frequencies in the plots.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"using CairoMakie\nCairoMakie.activate!(type = \"png\")\nf_min, f_max = 1e-3 * 5, 1e3 / 5\nS_low = S_high = 20\nfigs = run_diagnostics(priors[1:3, :], priors[4, :], f_min,f_max, SingleBendingPowerLaw, S_low,S_high, n_components=20, basis_function=\"SHO\")","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The following plots are produced: The mean of the residuals and ratios as a function of frequency.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"figs[1]# hide","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The quantiles of the residuals and ratios as a function of frequency.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"figs[2]# hide","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The distribution of the mean, median and maximum values of the frequency-averaged residuals and ratios.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"figs[3] # hide","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"Using these three diagnostics we can see that a SingleBendingPowerLaw with the chosen prior distributions can be well approximated with 20 SHO basis functions.","category":"page"},{"location":"modelling/#Building-the-Gaussian-process","page":"Modelling","title":"Building the Gaussian process","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"Now that we have checked that approximation hold for our choice of priors we can build the Gaussian process.","category":"page"},{"location":"modelling/#Building-the-covariance-function","page":"Modelling","title":"Building the covariance function","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The covariance function using the approximation of the power spectral density is obtained using the function approx. We need to specify the frequencies of the observations f_mathrmmin and f_mathrmmax and the scaling factors S_mathrmlow and S_mathrmhigh extending the grid of frequencies over which the approximation is performed; Following the notations presented above: f0=f_mathrmminS_mathrmlow and fM = f_mathrmmaxS_mathrmhigh, by default S_mathrmlow=S_mathrmhigh=20. We also need to set the number of basis functions to use, and the normalisation of the power spectrum. One can also give the type of basis function to use, the default is SHO which corresponds to the basis function psi_4, DRWCelerite corresponds to psi_6.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"ùìü = SingleBendingPowerLaw(.4, 1e-1, 3.)\n\nnormalisation = 2.2\nùì° = approx(ùìü, f_min, f_max, 20, normalisation, S_low, S_high, basis_function=\"SHO\",is_integrated_power=true)","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"info \"Normalisation of the power spectrum\"","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"As can be observed in the code, we also specify the optical argument is_integrated_power which tells if the normalisation corresponds to the integrated power between f_mathrmmin and f_mathrmmax. If not, the normalisation corresponds to mathcalR(0) the variance of the process which is the integral of the power spectrum between 0 and +infty. Both integrals can be computed analytically as described in: Integral of the basis functions.","category":"page"},{"location":"modelling/#Building-the-Gaussian-process-2","page":"Modelling","title":"Building the Gaussian process","text":"","category":"section"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The Gaussian process is built using the type ScalableGP. If the mean of the process mu is known, it can be given as a first argument. Otherwise, the mean is assumed to be zero.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"Œº = 1.3\nf = ScalableGP(Œº, ùì°)","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"At the moment, the GP does not include the measurement variance œÉ¬≤ and the time values t. This is done in the next step.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"using DelimitedFiles # hide\nA = readdlm(\"data/simu.txt\",comments=true) # hide\nt, y, yerr = A[:,1], A[:,2], A[:,3] # hide\nœÉ¬≤ = yerr .^ 2\nfx = f(t, œÉ¬≤)","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"The log-likelihood of the Gaussian process given the data y can be computed using the function logpdf from the Distributions package.","category":"page"},{"location":"modelling/","page":"Modelling","title":"Modelling","text":"logpdf(fx, y)","category":"page"},{"location":"simulations/#Simulations","page":"Simulations","title":"Simulations","text":"","category":"section"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"In addition to inference, the Gaussian process modelling framework allows simulations and predictions of the underlying process. This is done by conditioning the Gaussian process on some observations and then sampling from the conditioned distribution.","category":"page"},{"location":"simulations/#Sampling-from-the-Gaussian-process","page":"Simulations","title":"Sampling from the Gaussian process","text":"","category":"section"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"Assuming a SingleBendingPowerLaw we can draw realisations from the Gaussian process with a mean. First, we define the power spectral density function and plot it.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"using Random\nusing Plots\nusing Pioran\n\nrng = MersenneTwister(1234)\n# Define power spectral density function\nùìü = SingleBendingPowerLaw(0.3,1e-2,2.9)\nf_min, f_max = 1e-3, 1e3\nf0,fM = f_min/20.,f_max*20.\nf = 10 .^ range(log10(f0), log10(fM), length=1000)\nplot(f, ùìü(f), xlabel=\"Frequency (day^-1)\",ylabel=\"Power Spectral Density\",legend=false,framestyle = :box,xscale=:log10,yscale=:log10,lw=2)","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"Then we approximate it to form a covariance function. We then build the Gaussian process and draw realisations from it using rand.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"\nvariance = 15.2\n# Approximation of the PSD to form a covariance function\nùì° = approx(ùìü, f_min, f_max, 20, variance, basis_function=\"SHO\")\nŒº = 1.3\n# Build the GP\nf = ScalableGP(Œº, ùì°) # Define the GP\n\nT = 450 # days\nt = range(0, stop=T, length=1000)\nœÉ¬≤ = ones(length(t))*0.25\n\nfx = f(t, œÉ¬≤) # Gaussian process\nrealisations = [rand(rng,fx) for _ in 1:5]\nplot(t, realisations, label=\"Realisations\", xlabel=\"Time [days]\", framestyle = :box,ylabel=\"Value\")","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"info: Note\nSampling from a Gaussian process built with semi-separable covariance functions is very efficient. The time complexity is O(N) where N is the number of data points.","category":"page"},{"location":"simulations/#Conditioning-the-Gaussian-process","page":"Simulations","title":"Conditioning the Gaussian process","text":"","category":"section"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"We can compute the conditioned or posterior distribution of the Gaussian process given some observations. Let's use a subset of the realisations to condition the Gaussian process and then sample from the conditioned distribution.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"using StatsBase\nidx = sort(sample(1:length(t), 50, replace = false));\nt_obs = t[idx]\ny_obs = realisations[1][idx]\nyerr = 0.25*ones(length(t_obs))\nfx = f(t_obs, yerr.^2) # Gaussian process","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"We can compute the posterior distribution of the Gaussian process given the observations.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"fp = posterior(fx, y_obs) # Posterior distribution","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"The mean and standard deviation of this distribution, can be computed using the mean and std functions. The posterior covariance matrix can be computed using the cov function.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"m = mean(fp,t);\ns = std(fp,t);","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"We can plot the realisations, the observations and the posterior distribution.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"plot(t, realisations[1], label=\"Realisation\", xlabel=\"Time [days]\", framestyle = :box,ylabel=\"Value\")\nplot!(t_obs, y_obs,yerr=yerr, label=\"Observations\", seriestype=:scatter)\nplot!(t,m, ribbon=s,label=\"Posterior distribution\", lw=2)\nplot!(t,m,ribbon=2*s, label=nothing)","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"info: Note\nThe computation of the mean of the distribution is very efficient. The time complexity is O(N) where N is the number of data points. However, the computation of the covariance is very inefficient as the posterior covariance is not semi-separable.","category":"page"},{"location":"simulations/#Sampling-from-the-conditioned-distribution","page":"Simulations","title":"Sampling from the conditioned distribution","text":"","category":"section"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"We can draw realisations from the conditioned distribution using rand.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"samples_cond = rand(rng,fp,t,5);","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"We can plot the realisations, the observations and the posterior distribution.","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"plot(t_obs, y_obs,yerr=yerr, label=\"Observations\", seriestype=:scatter, xlabel=\"Time [days]\", framestyle = :box,ylabel=\"Value\",color=:black,lw=2)\nplot!(t, samples_cond, label=nothing)","category":"page"},{"location":"simulations/","page":"Simulations","title":"Simulations","text":"info: Note\nSampling from the conditioned Gaussian process is very inefficient as the posterior distribution is not semi-separable.","category":"page"},{"location":"getting_started/#Getting-started","page":"Getting Started","title":"Getting started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"This very brief tutorial introduces on how to obtain a likelihood function to fit a bending power-law power spectrum model to some time series data.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"As Pioran is written in Julia, you need to install Julia first. Please refer to the official website for the installation.","category":"page"},{"location":"getting_started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Once Julia is installed, you can install Pioran by running the following command in the Julia REPL:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"import Pkg; Pkg.add(\"Pioran\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"You may need to install other packages such as Distributions, Plots, DelimitedFiles to run the examples.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"note: Note\nAnother way to install packages in the Julia REPL is to use the ] key to enter the package manager and then type add MyPackage. See below:pkg> add Distributions Plots DelimitedFiles","category":"page"},{"location":"getting_started/#Usage","page":"Getting Started","title":"Usage","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"First, load the package using the following command:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Pioran","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Assuming you have a time series y  with measurement error yerr indexed by time t.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using DelimitedFiles # hide\nusing Plots\nA = readdlm(\"data/simu.txt\",comments=true) # hide\nt, y, yerr = A[:,1], A[:,2], A[:,3] # hide\nœÉ¬≤ = yerr .^ 2  # hide\nscatter(t, y,yerr=yerr, label=\"data\",xlabel=\"Time (days)\",ylabel=\"Value\",legend=false,framestyle = :box,ms=3)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's assume we can model the power spectrum with a single-bending power-law model SingleBendingPowerLaw. We can define a power spectral density (PSD) as follows:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ = 0.3, 0.03, 3.2\nùìü = SingleBendingPowerLaw(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can plot the PSD:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"f = 10 .^ range(-3, stop=3, length=1000)\nplot(f, ùìü.(f), label=\"Single Bending Power Law\",xlabel=\"Frequency (day^-1)\",ylabel=\"Power Spectral Density\",legend=true,framestyle = :box,xscale=:log10,yscale=:log10)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To compute the corresponding covariance function, we need to calculate the inverse Fourier transform of the PSD. However it is very hard, to my knowledge there is no closed form for this integral. We could use the discrete Fourier transform but it would be limiting in terms of performance and one would need to use interpolation to evaluate the function at any given point. Instead, we approximate the PSD model with a sum of basis functions named SHO or DRWCelerite using the approx function.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"f_min, f_max = 1/(t[end]-t[1]), 1/2/minimum(diff(t))\nnorm = 12.3\nùì° = approx(ùìü, f_min, f_max, 20, norm, basis_function=\"SHO\")","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The normalisation of the PSD is given using norm which corresponds to the integral of the PSD between f_min and f_max. More details about approximating the power spectral density can be found in the Approximating the power spectral density section of Modelling. We can also plot the autocovariance function:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"œÑ = range(0, stop=300, length=1000)\nplot(œÑ, ùì°.(œÑ,0.), label=\"Covariance function\",xlabel=\"Time lag (days)\",ylabel=\"Autocovariance\",legend=true,framestyle = :box)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can now build a Gaussian Process (GP) f which uses the quasi-separable structure of the covariance function to speed up the computations, see Foreman-Mackey et al. (2017). If the mean of the process mu is known, it can be given as an argument. Otherwise, the mean is assumed to be zero. The GP is constructed as follows:","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Œº = 1.3\nf = ScalableGP(Œº, ùì°)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can compute the log-likelihood of the Gaussian process given data y, times t and measurement variances œÉ¬≤ using the function logpdf from the Distributions package. f(t, œÉ¬≤) is the Gaussian process where we incorporate the knowledge of measurement variance œÉ¬≤ and the time values t.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using Distributions\nlogpdf(f(t, œÉ¬≤), y)","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We can combine all these steps in a function to build the GP and then compute the log-likelihood of the data given the parameters of the power spectral density and the Gaussian process.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"function GP_model(t, y, œÉ, params)\n\n    Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, norm, Œº = params\n\n    œÉ¬≤ = œÉ .^ 2\n\n    # Define power spectral density function\n    ùìü = SingleBendingPowerLaw(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximation of the PSD to form a covariance function\n    ùì° = approx(ùìü, f_min, f_max, 20, norm, basis_function=\"SHO\")\n\n    # Build the GP\n    GP = ScalableGP(Œº, ùì°)\n\n    # sample the conditioned distribution\n    return GP(t,œÉ¬≤)\nend\n\nfunction loglikelihood(t, y, œÉ, params)\n    GP = GP_model(t, y, œÉ, params)\n    return logpdf(GP, y)\nend","category":"page"},{"location":"custom_mean/#Using-custom-mean-function","page":"Using custom mean function","title":"Using custom mean function","text":"","category":"section"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"In some cases, we want to use a mean function that is not constant over time. For instance, this can be useful when one wants to model a periodic signal embedded in red noise.","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"Let's say we want to model a mean function of the form:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"m(t  A T_0 phimu) = A sin(2pi t  T_0 +phi) +mu","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"and the broadband noise is modelled with a power-law power spectrum, typical for the variability of active galaxies.","category":"page"},{"location":"custom_mean/#Implementation","page":"Using custom mean function","title":"Implementation","text":"","category":"section"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"using Plots\nusing Pioran\nusing Random\nusing Distributions","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"To use a custom mean function, first define the function like:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"mean_function(x, A=A, œï=œï, T‚ÇÄ=T‚ÇÄ, Œº=Œº) = @. A * sin(2œÄ * x / T‚ÇÄ + œï) + Œº","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"Then, create a CustomMean struct with the function as an argument:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"Œº_fun = CustomMean(mean_function)","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"And use it in the ScalableGP struct like any mean value and that's it! This whole process can be summarised in a function as follows:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"function GP_model(t, y, œÉ, params)\n\n    Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ, variance, ŒΩ, Œº, A, œï, T‚ÇÄ = params\n\n    T = (t[end] - t[1]) # duration of the time series\n    Œît = minimum(diff(t)) # min time separation\n    f_min, f_max = 1 / T, 1 / Œît / 2\n\n    # Rescale the measurement variance\n    œÉ¬≤ = ŒΩ .* œÉ .^ 2\n\n    # Define the mean\n    mean_function(x, A=A, œï=œï, T‚ÇÄ=T‚ÇÄ, Œº=Œº) = @. A * sin(2œÄ * x / T‚ÇÄ + œï) + Œº\n    Œº_fun = CustomMean(mean_function)\n\n    # Define the power spectral density function\n    ùìü = SingleBendingPowerLaw(Œ±‚ÇÅ, f‚ÇÅ, Œ±‚ÇÇ)\n\n    # Approximate  the PSD to form a covariance function\n    ùì° = approx(ùìü, f_min, f_max, 20, variance, basis_function=\"SHO\")\n\n    # Build the GP using the mean function and (auto)covariance function\n    f = ScalableGP(Œº_fun, ùì°)\n\n    # Condition on the times and errors of the observation\n    fx = f(t, œÉ¬≤)\n    return fx\nend","category":"page"},{"location":"custom_mean/#Sampling-from-the-GP","page":"Using custom mean function","title":"Sampling from the GP","text":"","category":"section"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"We first define the GP to sample from:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"t = LinRange(0,2000,200)\nœÉ = 0.5 * ones(length(t))\n\nparams = [0.3,1e-2,2.9,1.03,1.0,0.2,2.3,0.3,320]\nGP = GP_model(t, nothing, œÉ, params)","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"We now sample a few realisations from the GP and see that the realisations are indeed periodic.","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"rng = MersenneTwister(12)\ny = [rand(rng,GP) for i in 1:3]\nPlots.scatter(t,y,yerr=œÉ,xlabel=\"Time\",ylabel=\"Value\",legend=false,framestyle = :box,ms=3)","category":"page"},{"location":"custom_mean/#Inference","page":"Using custom mean function","title":"Inference","text":"","category":"section"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"To use such process for inference it is as easy as before. You need to get the loglikelihood using the logpdf function as follows:","category":"page"},{"location":"custom_mean/","page":"Using custom mean function","title":"Using custom mean function","text":"GP = GP_model(t,y, œÉ, params)\nlogpdf(GP,y[1])","category":"page"},{"location":"basis_functions/#About-the-basis-functions","page":"About the basis functions","title":"About the basis functions","text":"","category":"section"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"The basis functions psi_4 and psi_6 and their Fourier transforms have several properties.","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"psi_4(f) = dfrac11+f^4  psi_6(f) = dfrac11+f^6","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"beginalignbeginsplit\nphi_4(tau) = dfracpisqrt2 expleft(-pisqrt2tauright) left(cosleft(pisqrt2tauright)+sinleft(pisqrt2tauright)right)\nphi_6(tau) =dfracpi3leftexpleft(-2pi tauright)+expleft(-pitauright)left(cosleft(pisqrt3tauright)+sqrt3sinleft(pisqrt3tauright)right)rightendsplit\nendalign","category":"page"},{"location":"basis_functions/#Approximation","page":"About the basis functions","title":"Approximation","text":"","category":"section"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"When a model is approximated using a basis function, the celerite coefficients are:","category":"page"},{"location":"basis_functions/#SHO:-\\psi_4","page":"About the basis functions","title":"SHO: psi_4","text":"","category":"section"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"beginalign*\na = A_j f_j pisqrt2\nb =A_j f_j pi  sqrt2\nc = pi f_j sqrt2\nd = pi f_j sqrt2\nendalign*","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"A_j","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"and f_j are respectively the amplitudes and characteristic frequencies of the basis functions.","category":"page"},{"location":"basis_functions/#DRWCelerite:-\\psi_6","page":"About the basis functions","title":"DRWCelerite: psi_6","text":"","category":"section"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"For the celerite part of the basis function:","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"beginalign*\na = A_j f_j pi3\nb =A_j f_j pi  sqrt3\nc = pi f_j\nd = pi sqrt3 f_j\nendalign*","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"For the DRW part:","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"beginalign*\na = A_j f_j pi3\nb = 0\nc = 2pi f_j\nd = 0\nendalign*","category":"page"},{"location":"basis_functions/#Integral-of-the-basis-functions","page":"About the basis functions","title":"Integral of the basis functions","text":"","category":"section"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"We can also obtain the integral of the basis functions in the Fourier domain from f_mathrmmin and f_mathrmmax. This value is used as a normalisation of the covariance function.","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"For psi_4 we have:","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"    int dfraca dx(xc)^4+1 =dfracac4sqrt2 leftlnleft(dfracx^2+cxsqrt2+c^2x^2-cxsqrt2+c^2right)+2arctanleft(dfraccxsqrt2c^2-x^2right)right","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"For psi_6 we have:","category":"page"},{"location":"basis_functions/","page":"About the basis functions","title":"About the basis functions","text":"    int dfraca dx(xc)^6+1 =dfracac3 left arctan(xc) +dfracsqrt34lnleft(dfracx^2+xcsqrt3+c^2x^2-xcsqrt3+c^2right)+dfrac12arctanleft(dfracx^2-c^2xcright)right","category":"page"},{"location":"bibliography/#Bibliography","page":"Bibliography","title":"Bibliography","text":"","category":"section"},{"location":"bibliography/","page":"Bibliography","title":"Bibliography","text":"Belcher,¬†J.; Hampton,¬†J.¬†S. and Wilson,¬†G.¬†T. (1994). Parameterization of Continuous Time Autoregressive Models for Irregularly Sampled Time Series Data. Journal¬†of¬†the¬†Royal¬†Statistical¬†Society.¬†Series¬†B¬†(Methodological) 56, 141‚Äì155. Accessed on Jun 2, 2023.\n\n\n\nJones,¬†R.¬†H. (1981). FITTING A CONTINUOUS TIME AUTOREGRESSION TO DISCRETE DATA. In: Applied Time Series Analysis II, edited by FINDLEY,¬†D.¬†F. (Academic Press); pp.¬†651‚Äì682.\n\n\n\nJones,¬†R.¬†H. and Ackerson,¬†L.¬†M. (1990). Serial Correlation in Unequally Spaced Longitudinal Data. Biometrika 77, 721‚Äì731. Accessed on Jun 2, 2023.\n\n\n\nForeman-Mackey,¬†D.; Agol,¬†E.; Ambikasaran,¬†S. and Angus,¬†R. (2017). Fast and Scalable Gaussian Process Modeling with Applications to Astronomical Time Series. The¬†Astrophysical¬†Journal 154, 220, arXiv:1703.09710 [astro-ph.IM].\n\n\n\nKelly,¬†B.¬†C.; Becker,¬†A.¬†C.; Sobolewska,¬†M.; Siemiginowska,¬†A. and Uttley,¬†P. (2014). Flexible and Scalable Methods for Quantifying Stochastic Variability in the Era of Massive Time-domain Astronomical Data Sets. The¬†Astrophysical¬†Journal 788, 33, arXiv:1402.5978 [astro-ph.IM].\n\n\n\nLefkir,¬†M.; Vaughan,¬†S.; Huppenkothen,¬†D.; Uttley,¬†P. and Anilkumar,¬†V. (2025). Modelling variability power spectra of active galaxies from irregular time series. Monthly¬†Notices¬†of¬†the¬†Royal¬†Astronomical¬†Society 539, 1775‚Äì1795, arXiv:2501.05886 [astro-ph.GA].\n\n\n\nRasmussen,¬†C.¬†E. and Williams,¬†C.¬†K. (2006). Gaussian Processes for Machine Learning (The MIT Press).\n\n\n\n","category":"page"},{"location":"#Pioran","page":"Home","title":"Pioran","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pioran is a Julia package for the inference of bending power-law power spectra from arbitrarily sampled time series using scalable Gaussian processes.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This method was designed to aid the estimation of bending frequencies and slopes in the power spectra of irregularly sampled light curves of active galaxies but it can be applied to any time series data. The method is formally introduced in Lefkir et al. (2025) and uses the fast celerite algorithm of Foreman-Mackey et al. (2017).","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package can be installed add follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"import Pkg; Pkg.add(\"Pioran\")","category":"page"},{"location":"#Content","page":"Home","title":"Content","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = vcat([\"getting_started.md\"],Main.BASIC_PAGES,Main.ADVANCED_PAGES,[\"api.md\"])\nDepth = 2","category":"page"}]
}
