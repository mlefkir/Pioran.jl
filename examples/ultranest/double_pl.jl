#= Example script for the inference of a double bending power spectral density using Pioran and ultranest (python package).

run with:
```bash
julia double.jl data.txt
```
where `data.txt` is a file containing the time series data. The file should have three columns: time, flux, flux error.
The script will create a directory `inference` containing the results of the inference.

If you have MPI installed, you may want to run the script in parallel, using the following command:
```bash
mpirun -n 4 julia double.jl data.txt
```
where `-n 4` is the number of processes to use.

=#
# load MPI and initialise
using MPI
MPI.Init()
comm = MPI.COMM_WORLD

using Pioran
using Distributions
using Statistics
using Random
using DelimitedFiles
using PyCall
# load the python package ultranest
ultranest = pyimport("ultranest")
# define the random number generator
rng = MersenneTwister(123)

# get the filename from the command line
filename = ARGS[1]
fname = replace(split(filename, "/")[end], ".txt" => "_double")
dir = "inference/" * fname
plot_path = dir * "/plots/"
if !ispath(dir)
    mkpath(dir)
end

# Load the data and extract a subset for the analysis
A = readdlm(filename, comments = true, comment_char = '#')
t_all, y_all, yerr_all = A[:, 1], A[:, 2], A[:, 3]
t, y, yerr, xÌ„, va = extract_subset(rng, dir * "/" * fname, t_all, y_all, yerr_all);

# Frequency range for the approx and the prior
f_min, f_max = 1 / (t[end] - t[1]), 1 / minimum(diff(t)) / 2
f0, fM = f_min / 20.0, f_max * 20.0
min_f_b, max_f_b = f0 * 4.0, fM / 4.0

# F var^2 is distributed as a log-normal
Î¼áµ¥, Ïƒáµ¥ = -1.5, 1.0;
Î¼â‚™, Ïƒâ‚™Â² = 2Î¼áµ¥, 2(Ïƒáµ¥)^2;
Ïƒâ‚™ = sqrt(Ïƒâ‚™Â²)

# options for the approximation
basis_function = "SHO"
n_components = 20
model = DoubleBendingPowerLaw
posterior_checks = true
prior_checks = true

function GP_model(t, y, Ïƒ, params, n_components = n_components, basis_function = basis_function)

    Î±â‚, fâ‚, Î±â‚‚, fâ‚‚, Î±â‚ƒ, variance, Î½, Î¼ = params

    # Rescale the measurement variance
    ÏƒÂ² = Î½ .* Ïƒ .^ 2 ./ y .^ 2 #.- c) .^ 2

    # Make the flux Gaussian
    yn = log.(y) #.- c)

    # Define power spectral density function
    ð“Ÿ = model(Î±â‚, fâ‚, Î±â‚‚, fâ‚‚, Î±â‚ƒ)

    # Approximation of the PSD to form a covariance function
    ð“¡ = approx(ð“Ÿ, f_min, f_max, n_components, variance, basis_function = basis_function)

    # Build the GP
    f = ScalableGP(Î¼, ð“¡)

    # sample the conditioned distribution
    return f(t, ÏƒÂ²), yn
end

function loglikelihood(t, y, Ïƒ, params)
    fx, yn = GP_model(t, y, Ïƒ, params)
    return logpdf(fx, yn)
end

logl(pars) = loglikelihood(t, y, yerr, pars)

# Priors
function prior_transform(cube)
    Î±â‚ = quantile(Uniform(0.0, 1.25), cube[1])
    fâ‚ = quantile(LogUniform(min_f_b, max_f_b), cube[2])
    Î±â‚‚ = quantile(Uniform(Î±â‚, 4), cube[3])
    fâ‚‚ = quantile(LogUniform(fâ‚, max_f_b), cube[4])
    Î±â‚ƒ = quantile(Uniform(Î±â‚‚, 4), cube[5])
    variance = quantile(LogNormal(Î¼â‚™, Ïƒâ‚™), cube[6])
    Î½ = quantile(Gamma(2, 0.5), cube[7])
    Î¼ = quantile(Normal(xÌ„, 5 * sqrt(va)), cube[8])
    # c = quantile(LogUniform(1.0e-6, minimum(y) * 0.99), cube[9])
    return [Î±â‚, fâ‚, Î±â‚‚, fâ‚‚, Î±â‚ƒ, variance, Î½, Î¼] #, c]
end
paramnames = ["Î±â‚", "fâ‚", "Î±â‚‚", "fâ‚‚", "Î±â‚ƒ", "variance", "Î½", "Î¼"] #, "c"]

if MPI.Comm_rank(comm) == 0 && prior_checks
    unif = rand(rng, 9, 3000) # uniform samples from the unit hypercube
    priors = mapreduce(permutedims, hcat, [prior_transform(unif[:, i]) for i in 1:3000]') # transform the uniform samples to the prior
    run_diagnostics(priors[1:5, :], priors[6, :], f_min, f_max, model, path = plot_path, basis_function = basis_function, n_components = n_components)
end

println("Hello there! I am process $(MPI.Comm_rank(comm)) of $(MPI.Comm_size(comm))")

println("Running sampler...")
sampler = ultranest.ReactiveNestedSampler(paramnames, logl, resume = true, transform = prior_transform, log_dir = dir, vectorized = false)
results = sampler.run()
sampler.print_results()
sampler.plot()

if MPI.Comm_rank(comm) == 0 && posterior_checks
    samples = readdlm(dir * "/chains/equal_weighted_post.txt", skipstart = 1)
    paramnames_split = Dict(
        "psd" => ["Î±â‚", "fâ‚", "Î±â‚‚", "fâ‚‚", "Î±â‚ƒ"],
        "norm" => "variance",
        "scale_err" => "Î½",
        # "log_transform" => "c",
        "mean" => "Î¼"
    )
    GP_model2(t, y, Ïƒ, params) = GP_model(t, y, Ïƒ, params)[1]

    run_posterior_predict_checks(samples, paramnames, paramnames_split, t, y, yerr, model, GP_model2, true; path = plot_path, basis_function = basis_function, n_components = n_components)
end
