#= Example script for the inference of a periodic signal embedded in red noise modelled by a single bending power spectral density.

using Pioran and ultranest (python package).

run with:

julia script_name.jl data.txt

where `data.txt` is a file containing the time series data. The file should have three columns: time, flux, flux error.
The script will create a directory `inference` containing the results of the inference.

If you have MPI installed, you may want to run the script in parallel, using the following command:

mpirun -n 4 julia script.jl data.txt

where `-n 4` is the number of processes to use.

=#

# load MPI and initialise

using MPI
MPI.Init()
comm = MPI.COMM_WORLD

using Pioran
using Distributions
using Statistics
using Random
using DelimitedFiles
using PyCall

# load the python package ultranest
ultranest = pyimport("ultranest")
warnings = pyimport("warnings")
warnings.filterwarnings("ignore")

# define the random number generator
seed = 123
rng = MersenneTwister(123)

# get the filename from the command line
filename = ARGS[1]
fname = replace(split(filename, "/")[end], ".txt" => "_periodic_rednoise")
dir = "inference/" * fname * "_$(seed)_factor"
plot_path = dir * "/plots/"


# work on one process
if MPI.Comm_rank(comm) == 0
    if !ispath(dir)
        mkpath(dir)
    end

    # Load the data and extract a subset for the analysis
    A = readdlm(filename, comments = true, comment_char = '#')
    t_all, y_all, yerr_all = A[:, 1], A[:, 2], A[:, 3]

    t_all = t_all .- t_all[1]
    t, y, yerr, xÌ„, va = extract_subset(seed, dir * "/" * fname, t_all, y_all, yerr_all, take_log = false)
end

# wait
MPI.Barrier(comm)
# do it again but on the other ones

if MPI.Comm_rank(comm) != 0
    # Load the data and extract a subset for the analysis
    A = readdlm(filename, comments = true, comment_char = '#')
    t_all, y_all, yerr_all = A[:, 1], A[:, 2], A[:, 3]

    t_all = t_all .- t_all[1]
    t, y, yerr, xÌ„, va = extract_subset(seed, dir * "/" * fname, t_all, y_all, yerr_all, take_log = false)
end


T = (t[end] - t[1]) # duration of the time series
Î”t = minimum(diff(t)) # min time separation


# Frequency range for the approx and the prior
f_min, f_max = 1 / T, 1 / Î”t / 2
f0, fM = f_min / 20.0, f_max * 20.0
min_f_b, max_f_b = f0 * 4.0, fM / 4.0

# F var^2 is distributed as a log-normal
Î¼áµ¥, Ïƒáµ¥ = -1.5, 1.0;
Î¼â‚™, Ïƒâ‚™Â² = 2Î¼áµ¥, 2(Ïƒáµ¥)^2;
Ïƒâ‚™ = sqrt(Ïƒâ‚™Â²)

# options for the approximation
basis_function = "SHO" # Î±â‚‚ cannot be steeper than 4! with SHO
n_components = 20
model = SingleBendingPowerLaw
posterior_checks = true
prior_checks = false

""" function to build the Gaussian process
"""
function GP_model(t, y, Ïƒ, params, basis_function = basis_function, n_components = n_components, model = model)

    T = (t[end] - t[1]) # duration of the time series
    Î”t = minimum(diff(t)) # min time separation

    f_min, f_max = 1 / T, 1 / Î”t / 2

    Î±â‚, fâ‚, Î±â‚‚, variance, Î½, Î¼, A, Ï•, Tâ‚€ = params

    # Rescale the measurement variance
    ÏƒÂ² = Î½ .* Ïƒ .^ 2

    # Define the mean
    mean_function(x, A = A, Ï• = Ï•, Tâ‚€ = Tâ‚€, Î¼ = Î¼) = @. A * sin(2Ï€ * x / Tâ‚€ + Ï•) + Î¼

    Î¼_fun = CustomMean(mean_function)
    # Define power spectral density function
    ð“Ÿ = model(Î±â‚, fâ‚, Î±â‚‚)

    # Approximation of the PSD to form a covariance function
    ð“¡ = approx(ð“Ÿ, f_min, f_max, n_components, variance, basis_function = basis_function)

    # Build the GP
    f = ScalableGP(Î¼_fun, ð“¡)

    # Condition on the times and errors
    fx = f(t, ÏƒÂ²)
    return fx
end

function loglikelihood(t, y, Ïƒ, params)
    fx = GP_model(t, y, Ïƒ, params)
    return logpdf(fx, y)
end
logl(pars) = loglikelihood(t, y, yerr, pars)

# Priors should in the same order as in the likelihood
function prior_transform(cube)
    Î±â‚ = quantile(Uniform(0.0, 1.5), cube[1])
    fâ‚ = quantile(LogUniform(min_f_b, max_f_b), cube[2])
    Î±â‚‚ = quantile(Uniform(Î±â‚, 4.0), cube[3])
    variance = quantile(LogNormal(Î¼â‚™, Ïƒâ‚™), cube[4])
    Î½ = quantile(Gamma(2, 0.5), cube[5])
    Î¼ = quantile(Normal(xÌ„, 5 * sqrt(va)), cube[6])
    A = quantile(LogNormal(0.0, 1.0), cube[7])
    Ï• = quantile(Uniform(0.0, 2Ï€), cube[8])
    Tâ‚€ = quantile(Uniform(0, T), cube[9])
    return [Î±â‚, fâ‚, Î±â‚‚, variance, Î½, Î¼, A, Ï•, Tâ‚€]
end
paramnames = ["Î±â‚", "fâ‚", "Î±â‚‚", "variance", "Î½", "Î¼", "A", "Ï•", "Tâ‚€"]

if MPI.Comm_rank(comm) == 0 && prior_checks
    unif = rand(rng, 9, 3000) # uniform samples from the unit hypercube
    priors = mapreduce(permutedims, hcat, [prior_transform(unif[:, i]) for i in 1:3000]') # transform the uniform samples to the prior
    run_diagnostics(priors[1:3, :], priors[4, :], f_min, f_max, model, path = plot_path, basis_function = basis_function, n_components = n_components)
end

println("Hello world, I am $(MPI.Comm_rank(comm)) of $(MPI.Comm_size(comm))")

println("Running sampler...")
sampler = ultranest.ReactiveNestedSampler(paramnames, logl, resume = true, transform = prior_transform, log_dir = dir, vectorized = false)
results = sampler.run()
sampler.print_results()
sampler.plot()


if MPI.Comm_rank(comm) == 0 && posterior_checks
    samples = readdlm(dir * "/chains/equal_weighted_post.txt", skipstart = 1)

    # this dict helps splitting the samples in the various components
    paramnames_split = Dict(
        "psd" => ["Î±â‚", "fâ‚", "Î±â‚‚"],
        "norm" => "variance",
        "scale_err" => "Î½",
        "mean" => ["A", "Ï•", "Tâ‚€", "Î¼"]
    )

    run_posterior_predict_checks(samples, paramnames, paramnames_split, t, y, yerr, model, GP_model, false; plots = ["psd", "lsp", "timeseries"], plot_f_P = false, path = plot_path, basis_function = basis_function, n_components = n_components)
end
